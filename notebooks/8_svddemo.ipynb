{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVD Demonstration\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "Simon Shaw\n",
    "<https://www.brunel.ac.uk/people/simon-shaw>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses python</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td> \n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What this is about:\n",
    "\n",
    "You will see how ...\n",
    "\n",
    "- The SVD can be use to reduce the dimensionality of a data set\n",
    "- This workflow can be implemented in `numpy`.\n",
    "\n",
    "As usual our emphasis will be on *doing* rather than *proving*:\n",
    "*just enough: progress at pace*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assigned Reading\n",
    "\n",
    "\n",
    "This worksheet is self-contained given the material we have already covered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remembering $k$-NN for *penguins*\n",
    "\n",
    "We're going to recall how we used the $k$-NN's algorithm to predict penguin species\n",
    "from four columns of numerical data. \n",
    "\n",
    "After we cleaned up the data set by removing the NaN's we were left with $333$ rows of\n",
    "data - one row for each penguin. The four columns therefore total to $4\\times 333 = 1332$\n",
    "individual items of data. Some of this is held back for testing, so the training data\n",
    "set size isn't actually this big, but we do need all of this for training and testing.\n",
    "\n",
    "This is a very modest size when compared to some data sets. Later we will see the\n",
    "MNIST data set of digitized handwritten numerals, $0,1,2,\\ldots,9$.\n",
    "\n",
    "There are $70,000$ examples in numerical MNIST, and each example requires $28^2=784$\n",
    "numbers. The dataset therefore comprises\n",
    "$70,000\\times 28^2=54,880,000$ - **54 million** - numbers.\n",
    "\n",
    "It is useful to be able to reduce the amount of data down to just *its essence*. This\n",
    "results in less computer memory needed, and faster computing times - because there is\n",
    "less to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "So, the example below is hopefully quite easy to follow when set in the context of\n",
    "our previous sessions. The data set here is quite small, but the idea and technique\n",
    "we present is quite general.\n",
    "\n",
    "Let's start with our standard imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### In This Notebook WE WILL COMMIT a DATA SCIENCE CRIME\n",
    "\n",
    "Will you be able to spot it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll bring in the penguins data as before, clean it up,\n",
    "and re-implement our $k$-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp = sns.load_dataset('penguins')\n",
    "dfp2 = dfp.dropna()\n",
    "dfp2.isna().sum()\n",
    "dfp2 = dfp2.reset_index(drop=True)\n",
    "print(dfp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We are going to repeat our example where we used the $k$-NN classifier to\n",
    "predict the species in column zero from the numerical data in columns\n",
    "3 - 6 (indexed as 2 - 5).\n",
    "\n",
    "Here is that code again...\n",
    "\n",
    "We fit the model using the Manhattan metric:\n",
    "$\\Vert\\boldsymbol{x}^* - \\boldsymbol{x}_i\\Vert_1$, \n",
    "and then plot the confusion matrix and performance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create our labelled training and test data sets with 60/40 train/test split\n",
    "X = dfp2.iloc[:, 2:6].values\n",
    "y = dfp2.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# obtain the classifier and fit it using 2 nearest neighbours\n",
    "# and the Manhattan norm\n",
    "classifier = KNeighborsClassifier(n_neighbors=2, p=1)\n",
    "classifier.fit(X_train, y_train)# Now use the fitted model from the training data to predict\n",
    "# from the test data.\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a confusion matrix to assess the performance\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\"); print(cm)\n",
    "accsc = accuracy_score(y_test,y_pred);\n",
    "print(\"Accuracy:\", accsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cmplot = ConfusionMatrixDisplay(cm, display_labels=classifier.classes_)\n",
    "cmplot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the above we extracted the columns of input data into a numpy array.\n",
    "\n",
    "The array is called `X`. Here are the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(' The data type of X: ', type(X))\n",
    "print('     The shape of X: ', X.shape)\n",
    "print('The first four rows:\\n', X[0:4,:])\n",
    "print('  The last two rows:\\n', X[-2:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Can we get by with less data?\n",
    "\n",
    "We saw an example earlier, when we introduced binary classifiers, where we\n",
    "used just two columns, *bill depth* and *body mass* to predict gender.\n",
    "\n",
    "That's useful - four columns of data are instantly halved into just two.\n",
    "\n",
    "But we may have lost valuable infomation that was present in those\n",
    "dropped columns.\n",
    "\n",
    "**Can we drop half the columns but keep all the information?**\n",
    "\n",
    "Well, not quite, but we have see how we can approximate matrices using \n",
    "eigenvalues (square matrices only) or singular values.\n",
    "\n",
    "Here, `X` is a non-square matrix so we can take its SVD..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The SVD of `X` can be obtained from `np.linalg.svd()` as we now show.\n",
    "\n",
    "We also see below that `@` can be used for matrix multiplication: `A @ B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "U, S, VT = np.linalg.svd(X, full_matrices=False) # full_matrices=False - discussed later\n",
    "print(\"     U's  shape: \", U.shape)\n",
    "print(\"     VT's shape: \", VT.shape)\n",
    "print(\"      S's shape: \", S.shape)\n",
    "print(\"             S = \", S)\n",
    "print(\"diag(S)'s shape: \", np.diag(S).shape)\n",
    "print(\"allclose? (T/F): \", np.allclose(X, U @ np.diag(S) @ VT), end=' - ')\n",
    "print(\"|| X-U @ np.diag(S) @ VT || = \", np.linalg.norm( X-U @ np.diag(S) @ VT ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Look at the singular values. \n",
    "- They are always non-negative and `numpy` gives them to us in descending order.\n",
    "- What do you notice about them? Can you introduce the notion of **importance**?\n",
    "- Graphics will help us... Let's use a bar chart (sometimes termed a *scree* plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# in some contexts this is related to a scree plot\n",
    "print(\"S = \", S)\n",
    "plt.bar([1,2,3,4],S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# a log scale is sometimes preferable...\n",
    "print(\"S = \", S)\n",
    "plt.bar([1,2,3,4],S,log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have seen for the SVD that we can write, in general,\n",
    "$$\n",
    "\\boldsymbol{B} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T\n",
    "=\\sum_{j=1}^{p} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T\n",
    "$$\n",
    "\n",
    "In this $p$ is the rank of the matrix $\\boldsymbol{B}$. \n",
    "\n",
    "Let's apply this to $\\boldsymbol{X}$.\n",
    "\n",
    "Note: this is one of the times where we're using a symmetric letter,\n",
    "$\\boldsymbol{X}$, to denote a non-symmetric matrix. It can't be \n",
    "helped - this use of `X` is very standard in Machine Learning and\n",
    "it isn't wise to go against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using the SVD for $\\boldsymbol{X}$ we have,\n",
    "$$\n",
    "\\boldsymbol{X} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T\n",
    "=\\sum_{j=1}^{p} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T\n",
    "$$\n",
    "and we'll show below that $p=4$. We can examine these approximations:\n",
    "\n",
    "- $\\boldsymbol{X}_n = \\sum_{j=1}^{n} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T$\n",
    "\n",
    "for $n=1,2,\\ldots$. Think of $n$ as being the number of columns we retain in\n",
    "our data set. We'll elaborate later.\n",
    "\n",
    "In worksheet B you were encouraged to look up and use a python loop.\n",
    "We'll use that here, it has the form:\n",
    "\n",
    "```\n",
    "for k in range(0,3):\n",
    "  do something with k = 0,1,2 in turn\n",
    "now carry on with something else\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up a zero matrix to hold the approximations X1, X2, ...\n",
    "Xc = np.zeros(X.shape)\n",
    "print('The norm of X is    ', np.linalg.norm( X ) )\n",
    "# take more and more terms in the SVD expansion - starting with none\n",
    "for nc in range(0,1+S.shape[0]):\n",
    "  Xc = U[:, :nc] @ np.diag(S[:nc]) @ VT[:nc, :]\n",
    "  print('The norm of X-Xc is ',np.linalg.norm( X-Xc ) )\n",
    "print('X-Xc is close to zero (T/F)...', np.allclose(X,Xc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that the norm (size) of $\\boldsymbol{X}-\\boldsymbol{X}_1$ drops\n",
    "from $78,252$ to $507$, this is just $507/78252 = 0.7\\%$ of the size \n",
    "of $\\boldsymbol{X}$.\n",
    "\n",
    "This suggests that almost all the information contained in the four columns\n",
    "of penguins data is captured in just the first rank one SVD approximation.\n",
    "\n",
    "We see that $\\boldsymbol{X}-\\boldsymbol{X}_4$ is essentially zero. Telling us\n",
    "that $\\boldsymbol{X}$ is indeed a rank 4 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is a simpler way to code it. Recall that \n",
    "\n",
    "$$\n",
    "\\boldsymbol{X}_n\n",
    "= \\sum_{j=1}^{n} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T\n",
    "= \\sigma_1 \\boldsymbol{u}_1\\boldsymbol{v}_1^T\n",
    "+ \\sigma_2 \\boldsymbol{u}_2\\boldsymbol{v}_2^T\n",
    "+ \\cdots\n",
    "+ \\sigma_n \\boldsymbol{u}_n\\boldsymbol{v}_n^T\n",
    "$$\n",
    "\n",
    "the full expansion on the right of that expression can be emulated like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Xc = np.zeros(X.shape)\n",
    "Xc = Xc + S[0]*U[:,0:1] @ VT[0:1,:]\n",
    "print(np.linalg.norm(X - Xc))\n",
    "Xc = Xc + S[1]*U[:,1:2] @ VT[1:2,:]\n",
    "print(np.linalg.norm(X - Xc))\n",
    "Xc = Xc + S[2]*U[:,2:3] @ VT[2:3,:]\n",
    "print(np.linalg.norm(X - Xc))\n",
    "Xc = Xc + S[3]*U[:,3:4] @ VT[3:4,:]\n",
    "print(np.linalg.norm(X - Xc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or we could use a loop - to emulate the summation symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Xc = np.zeros(X.shape)\n",
    "nc = 4\n",
    "for k in range(0, nc):\n",
    "  Xc = Xc + S[k] * U[:,[k]] @ VT[[k],:]\n",
    "  print(np.linalg.norm( X-Xc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can now go back to the $k$-NN code and use this reduced data set \n",
    "in place of the full four columns.\n",
    "\n",
    "Remember: **we expect that the SVD has provided the essence of the four columns in less space**\n",
    "\n",
    "We will use the loop as above, and examine the performance of the classifier\n",
    "as it depends on `nc`.\n",
    "\n",
    "We'll set up a `numpy` array to store the accuracy score for each choice of `nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "accarray = np.zeros([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#X = dfp2.iloc[:, 2:6].values # we don't use the raw data this time\n",
    "Xc = np.zeros(X.shape)\n",
    "nc = 3\n",
    "for k in range(0, nc):\n",
    "  Xc = Xc + S[k] * U[:,[k]] @ VT[[k],:]\n",
    "y = dfp2.iloc[:, 0].values                         # Xc needed below\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, y, test_size=0.40)\n",
    "# scale the data\n",
    "scaler = StandardScaler(); scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# obtain classifier, fit using 2 NN's and the Manhattan norm\n",
    "classifier = KNeighborsClassifier(n_neighbors=2, p=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict from the test data.\n",
    "y_pred = classifier.predict(X_test)\n",
    "# create a confusion matrix to assess the performance\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\"); print(cm)\n",
    "accsc = accuracy_score(y_test,y_pred); print(\"Accuracy:\", accsc)\n",
    "print('nc = ', nc, ', ||X-Xc|| = ', np.linalg.norm(X - Xc))\n",
    "# store the accuracy scores in a python list for nc=1,2,3,4\n",
    "accarray[nc-1] = accsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A plot of the accuracy dependence on the number of singular values in\n",
    "use would be easier on the eye...\n",
    "\n",
    "*NOTE: this will not make sense in the static PDF, HTML versions as it will only have run once*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(accarray)\n",
    "plt.plot([1,2,3,4], accarray)\n",
    "plt.xlabel('Number of Singular Values')\n",
    "plt.ylabel('Accuracy estimate')\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Comments?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Have you SPOTTED THE CRIME YET?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review\n",
    "\n",
    "We are now making a lot of progress. We have seen our how our first machine learning\n",
    "algorithm, $k$-NN's, can be configured and used, how to deal with data using \n",
    "`seaborn` (with `pandas` in tha background), deal with plots using `matplotlib` and \n",
    "deal with number crunching vectors and matrices with `numpy`. All of this is within\n",
    "the convenient wrapper of the `python` programming language.\n",
    "\n",
    "In the last example we are also starting to see how we can manipulate and transform \n",
    "data to ask whether we need all of it or not. \n",
    "\n",
    "We have seen a very important technique, but what value of `nc` should we use?\n",
    "\n",
    "To answer such questions we need to think about what it is we are most interested in \n",
    "knowing.\n",
    "\n",
    "For example, here is our confusion matrix for the last computation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cmplot = ConfusionMatrixDisplay(cm, display_labels=classifier.classes_)\n",
    "cmplot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider these questions:\n",
    "\n",
    "1. Suppose a Chinstrap was prediced? What's the chance that it's an Adelie or Gentoo?\n",
    "1. What's the chance the prediction is correct?\n",
    "1. Which species are predicted most accurately?\n",
    "1. What is the probability that a Gentoo is incorrectly predicted?\n",
    "\n",
    "Have a think, How could you use the confusion matrix to answer these?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we need here is **Probability** and, later, **statistics**.\n",
    "\n",
    "They are the means by which we assert a *strength of belief* (probability) \n",
    "as well as describe results and make inferences with confidence (statistics).\n",
    "\n",
    "Next we'll get on to reviewing some essential parts of those areas but beforehand\n",
    "we want to close with some technical observations regarding the SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVD: The Singular Value Decomposition - some technicalities\n",
    "\n",
    "Let $\\boldsymbol{K}$ be an $n$-row by $m$-column matrix of real numbers.\n",
    "Then $\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$ -\n",
    "this is called the *Singular Value Decomposition* of $\\boldsymbol{K}$.\n",
    "In this:\n",
    "\n",
    "-   $\\boldsymbol{U}$ is an $n\\times n$ *orthogonal square* matrix\n",
    "-   $\\boldsymbol{\\Sigma}$ is an $n\\times m$ *rectangular diagonal*\n",
    "    matrix\n",
    "-   $\\boldsymbol{V}^T$ is an $m\\times m$ *orthogonal square* matrix\n",
    "\n",
    "The entries on the diagonal of $\\boldsymbol{\\Sigma}$ are called the\n",
    "*singular values* of $\\boldsymbol{K}$ and the number of non-zero\n",
    "singular values gives the rank of $\\boldsymbol{K}$.\n",
    "The columns of $\\boldsymbol{U}$ (resp. $\\boldsymbol{V}$) are called the\n",
    "left (resp. right) singular vectors of $\\boldsymbol{K}$.\n",
    "\n",
    "Let's look at the shapes of the matrices we have been using: we had\n",
    "$\\boldsymbol{X} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of X  is: ', X.shape, '\\t we knew this')\n",
    "print('The shape of U  is: ', U.shape, '\\t seems WRONG')\n",
    "print('The shape of S  is: ', S.shape, '\\t seems WRONG')\n",
    "print('The shape of VT is: ', VT.shape,'\\t seems OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's going on? Pictures will help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given $\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$, with \n",
    "`S` for $\\boldsymbol{\\Sigma}$, and using `+` to denote the non-zero diagonal\n",
    "elements, the shapes of these depend on the shape of $\\boldsymbol{K}$\n",
    "\n",
    "For $n=m$ they are,\n",
    "\n",
    "```\n",
    ".---------.    .---------. +---------. .---------. \n",
    "|         |    |         | | +       | |         | \n",
    "|    K    | =  |    U    | |    +    | |   V^T   | \n",
    "|         |    |         | | S     + | |         |  \n",
    "'---------'    '---------' '---------+ '---------'\n",
    "```\n",
    "This is the 'easy case' - it's just the eigenvalue problem ($\\boldsymbol{K}$\n",
    "need not be symmetric). There are two other cases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $n>m$ the shapes are,\n",
    "\n",
    "```\n",
    ".---------.    .------------------. +---------. .---------. \n",
    "|         |    |                  | | +       | |         | \n",
    "|         |    |                  | |   +     | |   V^T   | \n",
    "|         | =  |                  | |     +   | |         | \n",
    "|    K    |    |        U         | |       + | '---------'  \n",
    "|         |    |                  | |         |  \n",
    "|         |    |                  | |         |  \n",
    "|         |    |                  | |  S      |  \n",
    "'---------'    '------------------' '---------' \n",
    "\n",
    "```\n",
    "\n",
    "For $n<m$ the shapes are,\n",
    "\n",
    "```\n",
    ".------------------.    .---------. +------------------. .------------------. \n",
    "|                  |    |         | | +         S      | |                  | \n",
    "|        K         | =  |    U    | |   +              | |                  | \n",
    "|                  |    |         | |     +            | |                  |\n",
    "'------------------'    '---------' '-------+----------' |       V^T        |\n",
    "                                                         |                  |\n",
    "                                                         |                  |\n",
    "                                                         |                  |\n",
    "                                                         '------------------'\n",
    "```\n",
    "In each case $\\boldsymbol{S}$ mas a **zero submatrix**. We've seen this in our earlier example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have seen this example of\n",
    "$\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$ before:\n",
    "\n",
    "$$\n",
    "\\text{If }\n",
    "\\boldsymbol{K}=\\left(\\begin{array}{rrr}\n",
    "1  &  2 & 5 \\\\\n",
    "5  & -6 & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\text{ then }\n",
    "\\boldsymbol{U}=\\left(\\begin{array}{rr}\n",
    "  -0.06213\\ldots  & 0.99806\\ldots \\\\\n",
    "   0.99806\\ldots  & 0.06213\\ldots \\\\\n",
    "\\end{array}\\right),\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Sigma}=\\left(\\begin{array}{lll}\n",
    "7.88191\\ldots &                 0 & 0 \\\\\n",
    "0                 & 5.46584\\ldots & 0 \\\\\n",
    "\\end{array}\\right)\n",
    "\\text{ and }\n",
    "\\boldsymbol{V}=\\left(\\begin{array}{rrr}\n",
    " 0.62525\\ldots & 0.23944\\ldots &-0.74278\\ldots \\\\\n",
    "-0.77553\\ldots & 0.29699\\ldots &-0.55708\\ldots \\\\\n",
    " 0.08720\\ldots & 0.92437\\ldots & 0.37139\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "If we use these we can indeed check that\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "&\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\left(\\begin{array}{rr}\n",
    "  -0.062\\ldots  & 0.998\\ldots \\\\\n",
    "   0.998\\ldots  & 0.062\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{lll}\n",
    "7.881\\ldots &                 0 & 0 \\\\\n",
    "0                 & 5.465\\ldots & 0 \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    " 0.625\\ldots & 0.239\\ldots &-0.742\\ldots \\\\\n",
    "-0.775\\ldots & 0.296\\ldots &-0.557\\ldots \\\\\n",
    " 0.087\\ldots & 0.924\\ldots & 0.371\\ldots \\\\\n",
    "\\end{array}\\right)^T\n",
    "\\\\\n",
    "&\\qquad{} =\n",
    "\\left(\\begin{array}{rrr}\n",
    "1  &  2 & 5 \\\\\n",
    "5  & -6 & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "But look at the last column of $\\boldsymbol{S}$. It doesn't give us anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's remove it... It means we have lose the last column of $\\boldsymbol{V}^T$ \n",
    "(i.e. the last row of $\\boldsymbol{V}$) as well...\n",
    "\n",
    "\\begin{align}\n",
    "&\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n",
    "\\left(\\begin{array}{rr}\n",
    "  -0.062\\ldots  & 0.998\\ldots \\\\\n",
    "   0.998\\ldots  & 0.062\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{ll}\n",
    "7.881\\ldots &                 0  \\\\\n",
    "0                 & 5.465\\ldots  \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    " 0.625\\ldots & 0.239\\ldots &-0.742\\ldots \\\\\n",
    "-0.775\\ldots & 0.296\\ldots &-0.557\\ldots \\\\\n",
    "\\end{array}\\right)^T\n",
    "\\\\\n",
    "&\\qquad{} =\n",
    "\\left(\\begin{array}{rrr}\n",
    "1  &  2 & 5 \\\\\n",
    "5  & -6 & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "We still have $\\boldsymbol{K}$. Surprised? Let's check this in `numpy`... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "K = np.array([[1,2,5],[5,-6,1]])\n",
    "U, S, VT = np.linalg.svd(K)\n",
    "S1 = np.array([ [7.88191, 0], [0, 5.46584]])\n",
    "V1 = np.array([ [0.625, 0.239],[-0.775, 0.297],[0.087,0.924]])\n",
    "print( U @ S1 @ V1.T)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Convinced? These numbers are just close because of the low precision \n",
    "we used. We'll see how to do this properly below.\n",
    "\n",
    "What we have discovered here is the *Thin SVD*. It works like this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $n>m$ we lose columns on the right of $\\boldsymbol{U}$ to form $\\boldsymbol{U_1}$,\n",
    "and rows at the bottom of $\\boldsymbol{S}$ to form $\\boldsymbol{S}_1$\n",
    "\n",
    "```\n",
    ".---------.    .------------------. +---------. .---------. \n",
    "|         |    |             \"    | | +       | |         | \n",
    "|         |    |             \"    | |   +     | |   V^T   | \n",
    "|         | =  |             \"    | |     +   | |         | \n",
    "|    K    |    |        U1   \"    | | S1    + | '---------'  \n",
    "|         |    |             \"    | |\"\"\"\"\"\"\"\"\"|  \n",
    "|         |    |             \"    | |         |  \n",
    "|         |    |             \"    | |         |  \n",
    "'---------'    '------------------' '---------' \n",
    "\n",
    "```\n",
    "\n",
    "For $n<m$ we lose columns on the right of $\\boldsymbol{S}$ to form $\\boldsymbol{S_1}$,\n",
    "and columns at the right of $\\boldsymbol{V}$ to form $\\boldsymbol{V}_1$\n",
    "\n",
    "```\n",
    ".------------------.    .---------. +------------------. .------------------. \n",
    "|                  |    |         | | +   S1 \"         | |                  | \n",
    "|        K         | =  |    U    | |   +    \"         | |      V1^T        | \n",
    "|                  |    |         | |     +  \"         | |                  |\n",
    "'------------------'    '---------' '-------+\"---------' |                  |\n",
    "                                                         |\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"|\n",
    "                                                         |                  |\n",
    "                                                         |                  |\n",
    "                                                         '------------------'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at this in code... First get the SVD and look at what is returned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "K = np.array([[1,2,5],[5,-6,1]])\n",
    "U, S, VT = np.linalg.svd(K)\n",
    "print(U)\n",
    "print(S)\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here `S` is already truncated so we jusy use `np.diag(S)` to make\n",
    "it square. Also, as it is $\\boldsymbol{V}^T$ and\n",
    "not $\\boldsymbol{V}$ that is returned, we just have to slice the top \n",
    "two rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(K)\n",
    "print(U @ np.diag(S) @ VT[0:2,:])\n",
    "print('K - U @ np.diag(S) @ VT[0:2,:] is zero (T/F): ', np.allclose(K, U @ np.diag(S) @ VT[0:2,:]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose that we wanted to work with the full SVD, with all zeros included?\n",
    "\n",
    "Well, we show this by example. First, note two things:\n",
    "\n",
    "- `np.linalg.svd` returns $\\boldsymbol{V}^T$, not $\\boldsymbol{V}$.  \n",
    "- The shape of `S` doesn't agree with $\\boldsymbol{\\Sigma}$.\n",
    "\n",
    "So, we'll need to pad `S` - and then we can check the reconstruction $\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$.\n",
    "\n",
    "The padding is a bit awkward - here it is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "S = np.hstack(( np.diag(S), np.zeros((2,1)) ))\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can check the reconstruction\n",
    "$\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$.\n",
    "It is zero (to machine precision), as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(K - U @ S @ VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lastly: earlier we said we would explain `full_matrices=False` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "U, S, VT = np.linalg.svd(K, full_matrices=False)\n",
    "print(U)\n",
    "print(S)\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "U, S, VT = np.linalg.svd(K, full_matrices=True)\n",
    "print(U)\n",
    "print(S)\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With `False` the unwanted columns (or rows) of $\\boldsymbol{V}$ (or\n",
    "$\\boldsymbol{V}^T$) aren't returned - but `S` is still not a matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review\n",
    "\n",
    "There is a great deal that can be said about the SVD, but we're going to\n",
    "stay narrowly focussed and leave it here.\n",
    "\n",
    "- We have indicated its value in data science and machine learning for\n",
    "dimensionality reduction.\n",
    "\n",
    "- We have shown how to work with the *thin SVD* and the *full SVD* in\n",
    "`numpy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How about THAT CRIME?\n",
    "\n",
    "We used the test data in the SVD. Is that allowed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HOMEWORK REMINDER - very important\n",
    "\n",
    "\n",
    "In the lab we are going to see how the SVD can be used to compress data. \n",
    "\n",
    "We'll use **image compression** as an example:\n",
    "take a good quality jpeg colour photo (e.g. on your phone) of something vivid,\n",
    "detailed and colourful and save it on your account (One Drive, for example)\n",
    "so that your Jupyter notebook in Anaconda can use it.\n",
    "\n",
    "We are going to use the SVD to compress the image.\n",
    "\n",
    "**We may have already done this** - it will depend on the timetable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Technical Notes, Production and Archiving\n",
    "\n",
    "Ignore the material below. What follows is not relevant to the material being taught."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Production Workflow\n",
    "\n",
    "- Finalise the notebook material above\n",
    "- Clear and fresh run of entire notebook four times to populate `accarray` and get a plot\n",
    "- Create html slide show:\n",
    "  - `jupyter nbconvert --to slides 8_svddemo.ipynb `\n",
    "- Set `OUTPUTTING=1` below\n",
    "- Comment out the display of web-sourced diagrams\n",
    "- Clear and fresh run of entire notebook\n",
    "- Comment back in the display of web-sourced diagrams\n",
    "- Clear all cell output\n",
    "- Set `OUTPUTTING=0` below\n",
    "- Save\n",
    "- git add, commit and push to FML\n",
    "- copy PDF, HTML etc to web site\n",
    "  - git add, commit and push\n",
    "- rebuild binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some of this originated from\n",
    "\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n",
    "\n",
    "These lines create a back up of the notebook. They can be ignored.\n",
    "\n",
    "At some point this is better as a bash script outside of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "NBROOTNAME='8_svddemo'\n",
    "OUTPUTTING=0\n",
    "\n",
    "if [ $OUTPUTTING -eq 1 ]; then\n",
    "  jupyter nbconvert --to html $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.html ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.html\n",
    "  mv -f $NBROOTNAME.html ./formats/html/\n",
    "\n",
    "  jupyter nbconvert --to pdf $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.pdf ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pdf\n",
    "  mv -f $NBROOTNAME.pdf ./formats/pdf/\n",
    "\n",
    "  jupyter nbconvert --to script $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.py ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pys\n",
    "  mv -f $NBROOTNAME.py ./formats/py/\n",
    "else\n",
    "  echo 'Not Generating html, pdf and py output versions'\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
