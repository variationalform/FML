{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Decompositions\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "Simon Shaw\n",
    "<https://www.brunel.ac.uk/people/simon-shaw>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td> \n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this is about:\n",
    "\n",
    "You will be introduced to ...\n",
    "\n",
    "- Methods for decomposing matrices in to alternative forms.\n",
    "- Eigenvalues and Eigenvectors of square matrices.\n",
    "- The singular Value Decomposition for general matrices\n",
    "- Using `numpy` to compute these decompositions.\n",
    "\n",
    "As usual our emphasis will be on *doing* rather than *proving*:\n",
    "*just enough: progress at pace*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigned Reading\n",
    "\n",
    "For this worksheet you should read CVhapter 7 of [FCLA], and\n",
    "Chapters 4 of [MML].\n",
    "\n",
    "- MML: Mathematics for Machine Learning, by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong.\n",
    "  Cambridge University Press. <https://mml-book.github.io>.\n",
    "- FCLA: A First Course in Linear Algebra, by Ken Kuttler, \n",
    "  <https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)>\n",
    " \n",
    "All of the above can be accessed legally and without cost.\n",
    "\n",
    "There are also these useful references for coding:\n",
    "\n",
    "- PT: `python`: <https://docs.python.org/3/tutorial>\n",
    "- NP: `numpy`: <https://numpy.org/doc/stable/user/quickstart.html>\n",
    "- MPL: `matplotlib`: <https://matplotlib.org>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors\n",
    "\n",
    "Consider this matrix and vector,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\n",
    "= \\left(\\begin{array}{rrr}\n",
    " 3 & -2 & 4 \\\\\n",
    "-6 & 6 & -11 \\\\\n",
    " 6 & 2 & 5 \\\\\n",
    "\\end{array}\\right)\n",
    "\\qquad\\text{ and }\\qquad\n",
    "\\boldsymbol{x}\n",
    "= \\left(\\begin{array}{r}\n",
    "-2 \\\\\n",
    " 3 \\\\\n",
    " 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\qquad\\text{ then }\\qquad\n",
    "\\boldsymbol{B}\\boldsymbol{x}\n",
    "= \\left(\\begin{array}{r}\n",
    "-8 \\\\\n",
    " 19 \\\\\n",
    "-1 \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "and notice that $\\boldsymbol{B}$ *mixes up* $\\boldsymbol{x}$ to such an\n",
    "extent that $\\boldsymbol{B}\\boldsymbol{x}$ bears no relationship to the\n",
    "original $\\boldsymbol{x}$. This isn't so surprising when you think about\n",
    "it.\n",
    "\n",
    "We can do this in `python` using `numpy` as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = \n",
      " [[-8]\n",
      " [19]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "B = np.array( [[3, -2, 4],[-6, 6, -11],[ 6, 2, 5 ]])\n",
    "x = np.array([[-2], [3], [1]])\n",
    "f = B.dot(x)\n",
    "print('f = \\n', f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, consider this matrix with a different vector,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\n",
    "= \\left(\\begin{array}{rrr}\n",
    " 3 & -2 & 4 \\\\\n",
    "-6 & 6 & -11 \\\\\n",
    " 6 & 2 & 5 \\\\\n",
    "\\end{array}\\right)\n",
    "\\qquad\\text{ and }\\qquad\n",
    "\\boldsymbol{w}\n",
    "= \\left(\\begin{array}{r}\n",
    "-2 \\\\\n",
    " 5 \\\\\n",
    " 2 \\\\\n",
    "\\end{array}\\right).\n",
    "$$ This time,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\\boldsymbol{w}\n",
    "= \\left(\\begin{array}{rrr}\n",
    " 3 & -2 & 4 \\\\\n",
    "-6 & 6 & -11 \\\\\n",
    " 6 & 2 & 5 \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{r}\n",
    "-2 \\\\\n",
    " 5 \\\\\n",
    " 2 \\\\\n",
    "\\end{array}\\right)\n",
    "=\n",
    "\\left(\\begin{array}{r}\n",
    "-8 \\\\\n",
    " 20 \\\\\n",
    " 8 \\\\\n",
    "\\end{array}\\right)\n",
    "=\n",
    "4\\left(\\begin{array}{r}\n",
    "-2 \\\\\n",
    " 5 \\\\\n",
    " 2 \\\\\n",
    "\\end{array}\\right)\n",
    "=\n",
    "4\\boldsymbol{w}\n",
    "$$ So $\\boldsymbol{B}\\boldsymbol{w}=4\\boldsymbol{w}$, and all\n",
    "$\\boldsymbol{B}$ does is magnify $\\boldsymbol{w}$ to be $4$ times\n",
    "longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "use `python` to show that $\\frac{1}{4}\\boldsymbol{B}\\boldsymbol{w}-\\boldsymbol{w}=\\boldsymbol{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f - w = \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "result = \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array( [[3, -2, 4],[-6, 6, -11],[ 6, 2, 5 ]])\n",
    "w = np.array([[-2], [5], [2]])\n",
    "f = 0.25*B.dot(w)\n",
    "print('f - w = \\n', f-w) \n",
    "# or many other variants, such as\n",
    "print('result = \\n', 0.25*B.dot(w)-w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems more surprising. Here $4$ is called an *eigenvalue* ('own\n",
    "value') of $\\boldsymbol{B}$ and $\\boldsymbol{w}$ is the corresponding\n",
    "*eigenvector*.\n",
    "\n",
    "In general, for any square matrix $\\boldsymbol{B}$ the problem of\n",
    "finding scalars $\\lambda$ and vectors $\\boldsymbol{v}$ such that\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\\boldsymbol{v}=\\lambda\\boldsymbol{v}\n",
    "$$ is called an *eigenvalue problem*. The following facts are known to\n",
    "be true:\n",
    "\n",
    "> **The Eigenvalue Theorem.** Every square matrix of dimension $n$ has\n",
    "> $n$ eigenvalue-eigenvector pairs,\n",
    "> $(\\lambda_1,\\boldsymbol{v}_1), (\\lambda_2,\\boldsymbol{v}_2),\\ldots, (\\lambda_n,\\boldsymbol{v}_n)$.\n",
    "> The eigenvalues need not be distinct, and the eigenvector lengths are\n",
    "> arbitrary. **A matrix which has one or more zero eigenvalues is not\n",
    "> invertible.** On the other hand, **If the eigenvalues of a matrix are\n",
    "> all non-zero then that matrix is invertible**, and it has **full\n",
    "> rank**. The determinant of a matrix is the product of its eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "For $\\boldsymbol{B}$ above we have that\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\\boldsymbol{v}=\\lambda\\boldsymbol{v}\n",
    "$$\n",
    "\n",
    "for\n",
    "$(\\lambda_1,\\boldsymbol{v}_1), (\\lambda_2,\\boldsymbol{v}_2), (\\lambda_3,\\boldsymbol{v}_3)$\n",
    "given by\n",
    "\n",
    "$$\n",
    "9 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    " 17 \\\\\n",
    "-45 \\\\   \n",
    " 3 \\\\\n",
    "\\end{array}\\right),\n",
    "\\qquad\\text{ with }\\qquad\n",
    "1 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    "-1 \\\\\n",
    " 1 \\\\\n",
    " 1\n",
    "\\end{array}\\right)\n",
    "\\qquad\\text{ and }\\qquad\n",
    "4 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    "  -2 \\\\\n",
    "   5 \\\\\n",
    "   2\n",
    "\\end{array}\\right).\n",
    "$$\n",
    "\n",
    "We have already seen the case $\\lambda = 4$ and\n",
    "$\\boldsymbol{v}=(-2,5,2)^T$ above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors are not unique - they can be multiplied by an arbitrary\n",
    "(non-zero) scalar and they remain eigenvectors. For that reason it is\n",
    "usual to *normalize* an eigenvector by dividing through by its length,\n",
    "as given by the (Euclidean, Pythagorean) $2$-norm, $\\Vert\\cdot\\Vert_2$.\n",
    "For example, for $\\boldsymbol{v}=(-2,5,2)^T$ we have\n",
    "\n",
    "$$\n",
    "\\Vert\\boldsymbol{v}\\Vert_2 = \\sqrt{(-2)^2+5^2+2^2} = \\surd{33} \n",
    "$$\n",
    "\n",
    "which means that\n",
    "\n",
    "$$\n",
    "\\boldsymbol{v} = \\frac{1}{\\sqrt{33}}\\left(\\begin{array}{r}\n",
    "-2 \\\\ 5 \\\\ 2\n",
    "\\end{array}\\right)\n",
    "=\n",
    "\\left(\\begin{array}{r}\n",
    "  -0.348155311911396 \\\\\n",
    "   0.870388279778489 \\\\\n",
    "      0.348155311911395\n",
    "\\end{array}\\right)\n",
    "$$ is also an eigenvector for the eigenvalue $\\lambda = 4$.\n",
    "\n",
    "> **THINK ABOUT:** An eigenpair satisfies\n",
    "> $\\boldsymbol{B}\\boldsymbol{v}=\\lambda\\boldsymbol{v}$. Choose a\n",
    "> non-zero real number $\\alpha$ and write\n",
    "> $\\boldsymbol{w}=\\alpha\\boldsymbol{v}$. Is it true that\n",
    "> $\\boldsymbol{B}\\boldsymbol{w}=\\lambda\\boldsymbol{w}$? Can you see why\n",
    "> eigenvectors are not unique in length?\n",
    "\n",
    "> **THINK ABOUT:** If we choose $\\alpha = \\Vert\\boldsymbol{v}\\Vert_2^{-1}$\n",
    "> above what can you say about the value of $\\Vert\\boldsymbol{w}\\Vert_2$?\n",
    "\n",
    "If we normalize each of the eigenvectors above with their own length we\n",
    "get something like this (the decimals may go on for ever - why?):\n",
    "\n",
    "$$\n",
    "9 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    " 0.3527\\ldots \\\\\n",
    "-0.9336\\ldots \\\\   \n",
    " 0.0622\\ldots \\\\\n",
    "\\end{array}\\right),\n",
    "\\qquad\\text{ with }\\qquad\n",
    "1 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    "-0.5773\\ldots \\\\\n",
    " 0.5773\\ldots \\\\\n",
    " 0.5773\\ldots\n",
    "\\end{array}\\right)\n",
    "\\qquad\\text{ and }\\qquad\n",
    "4 \\text{ with }\n",
    "\\left(\\begin{array}{r}\n",
    "  -0.3481\\ldots \\\\\n",
    "   0.8703\\ldots \\\\\n",
    "   0.3481\\ldots\n",
    "\\end{array}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `numpy` to calculate the eigensystem for $\\boldsymbol{B}$.\n",
    "It goes like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 1. 4.]\n",
      "[[ 0.35271531 -0.57735027 -0.34815531]\n",
      " [-0.93365819  0.57735027  0.87038828]\n",
      " [ 0.06224388  0.57735027  0.34815531]]\n"
     ]
    }
   ],
   "source": [
    "w, V = np.linalg.eig(B)\n",
    "print(w)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yu can see that two quantities are returned, `w` and `V`. The eigenvalues are\n",
    "collected in `w` and the corresponding eigenvectors are the columns of `W`.\n",
    "\n",
    "Note that the third column of `W` agrees with our calculation above as the\n",
    "normalized eigenvector for the eigenvalue $\\lambda = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Eigen-System\n",
    "\n",
    "As indicated by this computation,\n",
    "we can stack the length-normalized eigenvectors together next to each\n",
    "other, with the eigenvalues in on the leading diagonal of an otherwise\n",
    "empty matrix. We also make sure that the eigenvectors appear in the same\n",
    "order as the corresponding eigenvalues and then use the fact that\n",
    "$\\boldsymbol{B}\\boldsymbol{v}=\\lambda \\boldsymbol{v}$ for each\n",
    "eigen-pair. Then entire eigen-system can then be represented in one\n",
    "equation. For example,\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\left(\\begin{array}{rrr}\n",
    " 3 & -2 & 4 \\\\\n",
    "-6 & 6 & -11 \\\\\n",
    " 6 & 2 & 5 \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    " 0.3527\\ldots & -0.5773\\ldots &  -0.3481\\ldots \\\\\n",
    "-0.9336\\ldots &  0.5773\\ldots &   0.8703\\ldots \\\\\n",
    " 0.0622\\ldots &  0.5773\\ldots &   0.3481\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "\\\\\\ \\\\\n",
    "\\qquad {}=\n",
    "\\left(\\begin{array}{rrr}\n",
    " 0.3527\\ldots & -0.5773\\ldots &  -0.3481\\ldots \\\\\n",
    "-0.9336\\ldots &  0.5773\\ldots &   0.8703\\ldots \\\\\n",
    " 0.0622\\ldots &  0.5773\\ldots &   0.3481\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    " 9 & 0 & 0 \\\\\n",
    " 0 & 1 & 0 \\\\\n",
    " 0 & 0 & 4 \\\\\n",
    "\\end{array}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We can write this as\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}\\boldsymbol{V} = \\boldsymbol{V}\\boldsymbol{D}\n",
    "$$\n",
    "\n",
    "where the columns of $\\boldsymbol{V}$ are the eigenvectors of\n",
    "$\\boldsymbol{B}$, and the diagonal matrix $\\boldsymbol{D}$ has the\n",
    "eigenvalues on the leading diagonal. The left-to-right order of the\n",
    "eigenvalues in $\\boldsymbol{D}$ matches the order that the eigenvectors\n",
    "appear in $\\boldsymbol{V}$.\n",
    "\n",
    "All three of these matrices are square and they each have the same\n",
    "dimension as $\\boldsymbol{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose that $\\det(\\boldsymbol{V})\\ne 0$, then\n",
    "$\\boldsymbol{V}^{-1}$ exists and we can (pre-)multiply both sides of\n",
    "$\\boldsymbol{B}\\boldsymbol{V} = \\boldsymbol{V}\\boldsymbol{D}$ by\n",
    "$\\boldsymbol{V}^{-1}$ and get,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{V}^{-1}\\boldsymbol{B}\\boldsymbol{V} =\n",
    "\\boldsymbol{V}^{-1}\\boldsymbol{V}\\boldsymbol{D} = \\boldsymbol{D}.\n",
    "$$\n",
    "\n",
    "We see that this has produced a diagonal matrix\n",
    "$\\boldsymbol{V}^{-1}\\boldsymbol{B}\\boldsymbol{V}$ that is similar to\n",
    "$\\boldsymbol{B}$ in the sense that it has the same eigenvalues. Such an\n",
    "operation is called a *similarity transformation*.\n",
    "\n",
    "On the other hand, we can (post-)multiply both sides of\n",
    "$\\boldsymbol{B}\\boldsymbol{V} = \\boldsymbol{V}\\boldsymbol{D}$ by\n",
    "$\\boldsymbol{V}^{-1}$ and get,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B} =\n",
    "\\boldsymbol{B}\\boldsymbol{V}\\boldsymbol{V}^{-1} =\n",
    "\\boldsymbol{V}\\boldsymbol{D}\\boldsymbol{V}^{-1}.\n",
    "$$\n",
    "\n",
    "One reason why this is useful is that we can now easily raise\n",
    "$\\boldsymbol{B}$ to powers. For example,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}^2 =\n",
    "(\\boldsymbol{V}\\boldsymbol{D}\\boldsymbol{V}^{-1})\n",
    "(\\boldsymbol{V}\\boldsymbol{D}\\boldsymbol{V}^{-1})\n",
    "=\\boldsymbol{V}\\boldsymbol{D}^2\\boldsymbol{V}^{-1}.\n",
    "$$ and so on.\n",
    "\n",
    "However, to do this we needed to assume that\n",
    "$\\det(\\boldsymbol{V})\\ne 0$, and this need not be the case. Matrices for\n",
    "which this is true are called *diagonalizable*, and matrices for which\n",
    "it isn't true are called *defective*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigen-systems of Symmetric Matrices\n",
    "\n",
    "The eigenvalues and eigenvectors of a general square matrix could be\n",
    "**complex numbers** (which we aren't going to be too concerned with),\n",
    "and for large matrices the inverse $\\boldsymbol{V}^{-1}$ could be hard\n",
    "to find explicitly.\n",
    "\n",
    "However, in the special case of a symmetric matrix $\\boldsymbol{A}$, the\n",
    "eigensystem $\\boldsymbol{A}\\boldsymbol{v}=\\lambda\\boldsymbol{A}$ is made\n",
    "up exclusively of *real numbers*.\n",
    "\n",
    "Furthermore, the matrix of normalized eigenvectors, $\\boldsymbol{V}$, is\n",
    "an orthogonal matrix. This means that\n",
    "$\\boldsymbol{V}^{-1}=\\boldsymbol{V}^T$ - which is very easy to\n",
    "calculate once $\\boldsymbol{V}$ is known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of this.\n",
    "\n",
    "$$\n",
    "\\text{if }\n",
    "\\boldsymbol{A} = \\left(\\begin{array}{rrr}\n",
    " 3 & -2 & 4  \\\\\n",
    "-2 &  6 & 2  \\\\\n",
    " 4 &  2 & 5\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "then (with some rounding),\n",
    "\n",
    "$$\n",
    "\\boldsymbol{D} \\approx \\left(\n",
    "\\begin{array}{rrr}\n",
    "-1.217 &  0     & 0 \\\\\n",
    " 0     &  8.217 & 0 \\\\\n",
    " 0     &  0     & 7  \n",
    "\\end{array}\n",
    "\\right) \\quad\\text{ and }\\quad \\boldsymbol{V} \\approx \\left(\n",
    "\\begin{array}{rrr}\n",
    " .726 & .522 & -.447 \\\\\n",
    " .363 & .261 &  .894 \\\\\n",
    "-.584 & .812 &  0 \\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- verify this with code.\n",
    "- verify that $\\boldsymbol{V}^{-1}=\\boldsymbol{V}^T$. Hint: `D=np.diag(w)`.\n",
    "- verify also that $\\boldsymbol{A}=\\boldsymbol{V}\\boldsymbol{D}\\boldsymbol{V}^T$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      " [[ 3 -2  4]\n",
      " [-2  6  2]\n",
      " [ 4  2  5]] \n",
      " w=\n",
      " [-1.21699057  8.21699057  7.        ] \n",
      " D=\n",
      " [[-1.21699057  0.          0.        ]\n",
      " [ 0.          8.21699057  0.        ]\n",
      " [ 0.          0.          7.        ]] \n",
      " V=\n",
      " [[ 7.26085219e-01  5.22302838e-01 -4.47213595e-01]\n",
      " [ 3.63042610e-01  2.61151419e-01  8.94427191e-01]\n",
      " [-5.83952325e-01  8.11787954e-01  2.85088132e-16]]\n",
      "V V^T = ...\n",
      " [[ 1.00000000e+00 -1.55686504e-16  3.16593922e-16]\n",
      " [-1.55686504e-16  1.00000000e+00 -3.00120936e-16]\n",
      " [ 3.16593922e-16 -3.00120936e-16  1.00000000e+00]]\n",
      "\n",
      " error ...\n",
      " [[-5.32907052e-15  2.66453526e-15 -3.55271368e-15]\n",
      " [ 2.22044605e-15  2.66453526e-15  4.44089210e-16]\n",
      " [-4.44089210e-15  6.66133815e-16  8.88178420e-16]]\n",
      "sum = -3.774758283725532e-15\n"
     ]
    }
   ],
   "source": [
    "# possible solution\n",
    "A = np.array([[3,-2,4],[-2,6,2],[4,2,5]])\n",
    "w, V = np.linalg.eig(A)\n",
    "D=np.diag(w)\n",
    "print('A=\\n',A,'\\n','w=\\n',w,'\\n','D=\\n',D,'\\n','V=\\n',V)\n",
    "print('V V^T = ...\\n',V.dot(V.T))\n",
    "print('\\n error ...\\n',A-V.dot(D.dot(V.T)))\n",
    "\n",
    "print('sum =', np.sum(A-V.dot(D.dot(V.T))) )\n",
    "assert np.sum(A-V.dot(D.dot(V.T))) < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation verifies that $\\boldsymbol{V}^T\\boldsymbol{V}=\\boldsymbol{I}$\n",
    "up to rounding error.\n",
    "\n",
    "Our check also confirms that $\\boldsymbol{A}\\boldsymbol{V}=\\boldsymbol{V}\\boldsymbol{D}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Eigen-Decomposition\n",
    "\n",
    "Furthermore, we can also write\n",
    "$\\boldsymbol{A}\\boldsymbol{V}=\\boldsymbol{V}\\boldsymbol{D}$ in expanded\n",
    "form,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} =\n",
    "(\\boldsymbol{v}_1\\ \\boldsymbol{v}_2\\ \\boldsymbol{v}_3\\ \\ldots)\n",
    "\\left(\\begin{array}{rrrr}\n",
    "\\lambda_1     \\\\\n",
    "& \\lambda_2   \\\\\n",
    "& & \\lambda_3 \\\\\n",
    "& & & \\ \\ \\ddots\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrrr}\n",
    "\\boldsymbol{v}_1^T\\\\ \\boldsymbol{v}_2^T\\\\ \\boldsymbol{v}_3^T\\\\ \\vdots\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "(we haven't shown all the zero elements) and then simplify this to get\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} =\n",
    "(\\boldsymbol{v}_1\\ \\boldsymbol{v}_2\\ \\boldsymbol{v}_3\\ \\ldots)\n",
    "\\left(\\begin{array}{cccc}\n",
    "\\lambda_1\\boldsymbol{v}_1^T \\\\\n",
    "\\lambda_2\\boldsymbol{v}_2^T \\\\\n",
    "\\lambda_3\\boldsymbol{v}_3^T \\\\ \\vdots\n",
    "\\end{array}\\right)\n",
    "=\n",
    "\\lambda_1\\boldsymbol{v}_1\\boldsymbol{v}_1^T\n",
    "+\n",
    "\\lambda_2\\boldsymbol{v}_2\\boldsymbol{v}_2^T\n",
    "+\n",
    "\\lambda_3\\boldsymbol{v}_3\\boldsymbol{v}_3^T\n",
    "+ \\cdots\n",
    "= \n",
    "\\sum_{k=1}^n\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "$$\n",
    "\n",
    "Let's see this in python. We start by getting the eigen-system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,-2,4],[-2,6,2],[4,2,5]])\n",
    "w, V = np.linalg.eig(A)\n",
    "D=np.diag(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each decomposed term in turn. First, for the $k=1$ term,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.64159712 -0.32079856  0.51600297]\n",
      " [-0.32079856 -0.16039928  0.25800148]\n",
      " [ 0.51600297  0.25800148 -0.41499417]]\n"
     ]
    }
   ],
   "source": [
    "print( D[0,0]*V[:,0:1]*V[:,0:1].T )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about what is going on here. We are printing out the quantity\n",
    "\n",
    "```python\n",
    "D[0,0]*V[:,0:1]*V[:,0:1].T\n",
    "```\n",
    "\n",
    "In this, the `D[0,0]` factor is just the eigenvalue from the top left\n",
    "(first row, first column) of the $\\boldsymbol{D}$ matrix. \n",
    "\n",
    "Then, next, `V[:,0:1]` is a `numpy` **slice**.\n",
    "\n",
    "In this type of expression `[c,a:b]` means take the elements in row `c` \n",
    "that occupy columns `a` through to `b-1`. The expression `[:,a:b]` means\n",
    "take all the rows. Remember that column and row numbering starts at zero\n",
    "in `numpy`.\n",
    "\n",
    "So, `V[:,0:1]` says take the first column of `V` - a column vector, \n",
    "and `V[:,0:1].T` says take the transpose of the first solumn of `V`.\n",
    "\n",
    "It is important to note that we have to write our slicing\n",
    "expressions in the form  `V[:,0:1]` rather than `V[:,0]`,\n",
    "otherwise we lose the shape. See e.g.\n",
    "<https://stackoverflow.com/questions/29635501/row-vs-column-vector-return-during-numpy-array-slicing>\n",
    "\n",
    "Here is a demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = \n",
      " [[ 7.26085219e-01  5.22302838e-01 -4.47213595e-01]\n",
      " [ 3.63042610e-01  2.61151419e-01  8.94427191e-01]\n",
      " [-5.83952325e-01  8.11787954e-01  2.85088132e-16]]\n",
      "V[:,0:1] = \n",
      " [[ 0.72608522]\n",
      " [ 0.36304261]\n",
      " [-0.58395233]]\n",
      "V[:,0] = \n",
      " [ 0.72608522  0.36304261 -0.58395233]\n"
     ]
    }
   ],
   "source": [
    "print('V = \\n', V)\n",
    "print('V[:,0:1] = \\n', V[:,0:1])\n",
    "print('V[:,0] = \\n', V[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, for $k=1$ we can write $\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T$\n",
    "in code as `D[0,0]*V[:,0:1]*V[:,0:1].T`.\n",
    "\n",
    "The full reconstruction of $\\boldsymbol{A}$ is then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The reconstruction of A ...\n",
      "[[ 3. -2.  4.]\n",
      " [-2.  6.  2.]\n",
      " [ 4.  2.  5.]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n The reconstruction of A ...')\n",
    "print(D[0,0]*V[:,0:1]*V[:,0:1].T + D[1,1]*V[:,1:2]*V[:,1:2].T + D[2,2]*V[:,2:3]*V[:,2:3].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Find the eigen-decomposition of the matrix\n",
    "\n",
    "$$\n",
    "\\boldsymbol{T} = \\left(\\begin{array}{rrr}\n",
    " 7 & -3 & -9 \\\\\n",
    "-3 & -5 &  2 \\\\\n",
    "-9 &  2 & 10\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Order the eigenvalues so that \n",
    "$\\vert\\lambda_1\\vert \\ge \\vert\\lambda_2\\vert \\ge \\vert\\lambda_3\\vert$ \n",
    "and determine the partial recontructions,\n",
    "\n",
    "- $\\boldsymbol{T}_1 = \\lambda_1\\boldsymbol{v}_1\\boldsymbol{v}_1^T$\n",
    "- $\\boldsymbol{T}_2 = \\lambda_1\\boldsymbol{v}_1\\boldsymbol{v}_1^T + \\lambda_2\\boldsymbol{v}_2\\boldsymbol{v}_2^T$\n",
    "\n",
    "Finally, check that $\\boldsymbol{T}_3 = \\boldsymbol{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  [18.14414013 -0.43436748 -5.70977265]\n"
     ]
    }
   ],
   "source": [
    "# possible solution\n",
    "T = np.array([[7,-3,-9],[-3,-5,2],[-9,2,10]])\n",
    "w, V = np.linalg.eig(T)\n",
    "# look at the eigenvalues to manually sort them...\n",
    "print('lambda = ', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that $\\vert\\lambda_1\\vert > \\vert\\lambda_3\\vert > \\vert\\lambda_2\\vert$\n",
    "and so, we can select them out in the correct order manually like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 = \n",
      " [[ 7.55329941 -1.7372557  -8.77369555]\n",
      " [-1.7372557   0.39956808  2.0179463 ]\n",
      " [-8.77369555  2.0179463  10.19127264]]\n",
      "T2 = \n",
      " [[ 7.22886142 -3.05895812 -8.79129842]\n",
      " [-3.05895812 -4.98481151  1.94623536]\n",
      " [-8.79129842  1.94623536 10.19031757]]\n",
      "T-T3 = \n",
      " [[-4.44089210e-15  2.66453526e-15  7.10542736e-15]\n",
      " [ 2.66453526e-15  8.88178420e-16 -8.88178420e-16]\n",
      " [ 7.10542736e-15 -8.88178420e-16 -8.88178420e-15]]\n"
     ]
    }
   ],
   "source": [
    "D=np.diag(w)\n",
    "T1 = D[0,0]*V[:,0:1]*V[:,0:1].T       # using lambda_1\n",
    "T2 = T1 + D[2,2]*V[:,2:3]*V[:,2:3].T  # using lambda_2\n",
    "T3 = T2 + D[1,1]*V[:,1:2]*V[:,1:2].T  # using lambda_3\n",
    "print('T1 = \\n', T1)\n",
    "print('T2 = \\n', T2)\n",
    "print('T-T3 = \\n', T-T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implication: approximation of matrices\n",
    "\n",
    "This is quite a big deal, it means in effect that we can break a square\n",
    "symmetric matrix into pieces and consider as many or as few of those\n",
    "pieces as we wish.\n",
    "\n",
    "This point of view really suggests an approximation scheme.\n",
    "If $\\boldsymbol{A}$ is $n\\times n$ symmetric then\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} =\n",
    "\\sum_{k=1}^n\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "\\qquad\\text{ which suggests that }\\qquad\n",
    "\\boldsymbol{A} \\approx\n",
    "\\sum_{k=1}^m\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "$$\n",
    "\n",
    "for $m < n$. We would want to sort the eigenvalues so that the\n",
    "most dominant ones come first in this sum, which is the same saying\n",
    "\n",
    "$$\n",
    "\\vert\\lambda_1\\vert \\ge\n",
    "\\vert\\lambda_2\\vert \\ge\n",
    "\\vert\\lambda_3\\vert \\ge  \\cdots\n",
    "$$\n",
    "\n",
    "And this is exactly what we did above.\n",
    "\n",
    "We'll look more closely at this in the workshop session. And,\n",
    "we'll also see a related demonstration of this idea later for an example in\n",
    "image compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. If $\\boldsymbol{A}$ is $n\\times n$ symmetric then how many independent\n",
    "quantities does it contain?\n",
    "\n",
    "2. If we approximate \n",
    "$$\n",
    "\\boldsymbol{A} =\n",
    "\\sum_{k=1}^n\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "\\qquad\\text{ by }\\qquad\n",
    "\\boldsymbol{A} \\approx\n",
    "\\sum_{k=1}^m\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "$$\n",
    "for some $k<$n, then how many independent quantities does this expression contain?\n",
    "\n",
    "3. What is the ratio of approximate size to exact size?\n",
    "\n",
    "4. Evaluate that ratio when $m=5$ and $n=1000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible Solution\n",
    "\n",
    "1. There are $n^2$ entries in the matrix but those under the diagonal \n",
    "are replicated above the diagonal. Hence, by adding the length of\n",
    "the diagonal to the first, and then second, and then third, ...,\n",
    "super-diagonals there are\n",
    "$$\n",
    "n+(n-1) + (n-2) + \\cdots + 2 + 1 = \\frac{(n+1)n}{2}\n",
    "$$\n",
    "2. $\\boldsymbol{v}_k$ has $n$ entries, and $\\lambda_k$ is just one number.\n",
    "Hence this expression has just $m(n+1)$.\n",
    "\n",
    "3. The ratio is therefore\n",
    "\n",
    "$$\n",
    "m(n+1)\\div\\frac{n(n+1)}{2}\n",
    "= \n",
    "\\frac{2m(n+1)}{n(n+1)}\n",
    "= \n",
    "\\frac{2m}{n}\n",
    "$$\n",
    "\n",
    "4. $m=5$ and $n=1000$ gives the ratio\n",
    "$\\displaystyle\\frac{2m}{n}=\\frac{2\\times 5}{1000} = 1\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that if a large matrix can be well approximated by just a few \n",
    "terms in the eigen-expansion then the amoint of storage required in computer\n",
    "memory can be vastly reduced.\n",
    "\n",
    "This is very useful. But it only applies to symmetric square matrices.\n",
    "We can extend it to non-symmetric matrices by introducing complex\n",
    "numbers but we can't extend this to non-square matrices because they\n",
    "don't have eigenvalues.\n",
    "\n",
    "Fortunately, there is another - even more powerful - tool at our\n",
    "disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulae\n",
    "\n",
    "For $\\boldsymbol{B}\\in\\mathbb{R}^{m\\times n}$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T\n",
    "=\\sum_{j=1}^{p} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T\n",
    "$$\n",
    "\n",
    "where: $\\boldsymbol{U}\\in\\mathbb{R}^{m\\times m}$,\n",
    "$\\boldsymbol{\\Sigma}\\in\\mathbb{R}^{m\\times n}$, $\\boldsymbol{V}\\in\\mathbb{R}^{n\\times n}$\n",
    "and $p=\\min\\{m,n\\}$. Note that $\\boldsymbol{\\Sigma}=\\text{diag}(\\sigma_1,\\ldots,\\sigma_p)$\n",
    "and we can always arrange this so that $0 \\le \\sigma_1\\le\\cdots\\le\\sigma_p$.\n",
    "\n",
    "$\\boldsymbol{B}$ is real here, then $\\boldsymbol{U}$ and $\\boldsymbol{V}$\n",
    "are real and *orthogonal*.\n",
    "\n",
    "If $\\sigma_r\\ne 0$ and $\\sigma_p= 0$ for all $p>r$ then\n",
    "$r$ is the rank of $\\boldsymbol{B}$.\n",
    "\n",
    "Note storage for $\\boldsymbol{B}$ is $mn$. That for the SVD is \n",
    "$r(m+n+1)$. The ratio is\n",
    "\n",
    "$$\n",
    "\\frac{r(m+n+1)}{mn} \n",
    "= \\frac{r}{n}\n",
    "+ \\frac{r}{m} \n",
    "+ \\frac{r}{mn} \n",
    "$$\n",
    "\n",
    "**BEWARE** that python indices start at zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Thin SVD\n",
    "\n",
    "Here we still have $\\boldsymbol{B}\\in\\mathbb{R}^{m\\times n}$ but with\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B} = \\boldsymbol{U}_1\\boldsymbol{\\Sigma}_1\\boldsymbol{V}^T\n",
    "=\\sum_{j=1}^{n} \\sigma_j \\boldsymbol{u}_j\\boldsymbol{v}_j^T\n",
    "$$\n",
    "\n",
    "where: $\\boldsymbol{U}_1\\in\\mathbb{R}^{m\\times n}$,\n",
    "$\\boldsymbol{\\Sigma}_1\\in\\mathbb{R}^{n\\times n}$. This is called the *thin SVD*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD: The Singular Value Decomposition\n",
    "\n",
    "The other two formulae calls are verified with the Golub, Van Loan book.\n",
    "\n",
    "Only square matrices have eigenvalues, and not all square matrices are\n",
    "diagonalizable via the similarity transform. For general matrices\n",
    "containing real numbers there is a tool called the **SVD** - the\n",
    "*Singular Value Decomposition*.\n",
    "\n",
    "Let $\\boldsymbol{K}$ be an $n$-row by $m$-column matrix of real numbers.\n",
    "Then\n",
    "$\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$ -\n",
    "this is called the *Singular Value Decomposition* of $\\boldsymbol{K}$.\n",
    "In this:\n",
    "\n",
    "-   $\\boldsymbol{U}$ is an $n\\times n$ *orthogonal square* matrix\n",
    "-   $\\boldsymbol{\\Sigma}$ is an $n\\times m$ *rectangular diagonal*\n",
    "    matrix\n",
    "-   $\\boldsymbol{V}^T$ is an $m\\times m$ *orthogonal square* matrix\n",
    "\n",
    "The entries on the diagonal of $\\boldsymbol{\\Sigma}$ are called the\n",
    "*singular values* of $\\boldsymbol{K}$ and the number of non-zero\n",
    "singular values gives the rank of $\\boldsymbol{K}$.\n",
    "\n",
    "The columns of $\\boldsymbol{U}$ (resp. $\\boldsymbol{V}$) are called the\n",
    "left (resp. right) singular vectors of $\\boldsymbol{K}$.\n",
    "\n",
    "Let's see an example of\n",
    "$\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$.\n",
    "\n",
    "$$\n",
    "\\text{If }\n",
    "\\boldsymbol{K}=\\left(\\begin{array}{rrr}\n",
    "1  &  2 & 5 \\\\\n",
    "5  & -6 & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\text{ then }\n",
    "\\boldsymbol{U}=\\left(\\begin{array}{rr}\n",
    "  -0.06213\\ldots  & 0.99806\\ldots \\\\\n",
    "   0.99806\\ldots  & 0.06213\\ldots \\\\\n",
    "\\end{array}\\right),\n",
    "$$ $$\n",
    "\\boldsymbol{\\Sigma}=\\left(\\begin{array}{rrr}\n",
    "7.88191\\ldots &                 0 & 0 \\\\\n",
    "0                 & 5.46584\\ldots & 0 \\\\\n",
    "\\end{array}\\right)\n",
    "\\text{ and }\n",
    "\\boldsymbol{V}=\\left(\\begin{array}{rrr}\n",
    " 0.62525\\ldots & 0.23944\\ldots &-0.74278\\ldots \\\\\n",
    "-0.77553\\ldots & 0.29699\\ldots &-0.55708\\ldots \\\\\n",
    " 0.08720\\ldots & 0.92437\\ldots & 0.37139\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "If we use these we can indeed check that\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "&\\left(\\begin{array}{rr}\n",
    "  -0.062\\ldots  & 0.998\\ldots \\\\\n",
    "   0.998\\ldots  & 0.062\\ldots \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    "7.881\\ldots &                 0 & 0 \\\\\n",
    "0                 & 5.465\\ldots & 0 \\\\\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{rrr}\n",
    " 0.625\\ldots & 0.239\\ldots &-0.742\\ldots \\\\\n",
    "-0.775\\ldots & 0.296\\ldots &-0.557\\ldots \\\\\n",
    " 0.087\\ldots & 0.924\\ldots & 0.371\\ldots \\\\\n",
    "\\end{array}\\right)^T\n",
    "\\\\\n",
    "&\\qquad{} =\n",
    "\\left(\\begin{array}{rrr}\n",
    "1  &  2 & 5 \\\\\n",
    "5  & -6 & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "as required. We aren't going to do it by hand though, that's what\n",
    "computers are for!\n",
    "\n",
    "There is a great deal that can be said about the SVD, but we're going to\n",
    "stay narrowly focussed and explore its value in data science and machine\n",
    "learning.\n",
    "\n",
    "``` bash\n",
    "K =\n",
    "\n",
    "     1     2     5\n",
    "     5    -6     1\n",
    "\n",
    ">> [U, S, V] = svd(K)\n",
    "\n",
    "U =\n",
    "\n",
    "  -0.062137441556329   0.998067602097590\n",
    "   0.998067602097590   0.062137441556329\n",
    "\n",
    "\n",
    "S =\n",
    "\n",
    "   7.881910650127741                   0                   0\n",
    "                   0   5.465847098428834                   0\n",
    "\n",
    "\n",
    "V =\n",
    "\n",
    "   0.625254559166026   0.239442265089237  -0.742781352708207\n",
    "  -0.775532832968505   0.296991577997824  -0.557086014531156\n",
    "   0.087209868879293   0.924371897175211   0.371390676354104\n",
    "\n",
    ">> K=U*S*V'\n",
    "\n",
    "K =\n",
    "\n",
    "   1.000000000000000   2.000000000000000   5.000000000000000\n",
    "   5.000000000000000  -6.000000000000001   1.000000000000000\n",
    "```\n",
    "\n",
    "Let's start with the following observation. If we denote the $n$-th\n",
    "column of $\\boldsymbol{U}$ by $\\boldsymbol{u}_n$, and the $n$-th column\n",
    "of $\\boldsymbol{V}$ by $\\boldsymbol{v}_n$, then the statement\n",
    "$\\boldsymbol{K} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T$\n",
    "becomes (we saw something very similar to this above with eigenvalues),\n",
    "\n",
    "$$\n",
    "\\boldsymbol{K}\n",
    "=\n",
    "(\\boldsymbol{u}_1\\ \\boldsymbol{u}_2\\ \\cdots\\ \\boldsymbol{u}_n)\n",
    "\\left(\\begin{array}{rrrr}\n",
    "\\sigma_1 & & & \\\\\n",
    " & \\sigma_2 & & \\\\\n",
    " & & \\ddots & \\\\\n",
    " & & & \\sigma_n\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{r}\n",
    "\\boldsymbol{v}_1^T \\\\\n",
    "\\boldsymbol{v}_2^T \\\\\n",
    "\\vdots\\  \\\\\n",
    "\\boldsymbol{v}_n^T \\\\\n",
    "\\end{array}\\right)\n",
    "=\n",
    "(\\boldsymbol{u}_1\\ \\boldsymbol{u}_2\\ \\cdots\\ \\boldsymbol{u}_n)\n",
    "\\left(\\begin{array}{r}\n",
    "\\sigma_1\\boldsymbol{v}_1^T \\\\\n",
    "\\sigma_2\\boldsymbol{v}_2^T \\\\\n",
    "\\vdots\\  \\\\\n",
    "\\sigma_n\\boldsymbol{v}_n^T \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "(we haven't shown all the zero elements of $\\boldsymbol{\\Sigma}$).\n",
    "Simplifying this further then gives,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{K}\n",
    "=\n",
    "\\sigma_1\\boldsymbol{u}_1\\boldsymbol{v}_1^T\n",
    "+ \\sigma_2\\boldsymbol{u}_2\\boldsymbol{v}_2^T\n",
    "+ \\cdots\n",
    "+ \\sigma_n\\boldsymbol{u}_n\\boldsymbol{v}_n^T\n",
    "$$\n",
    "\n",
    "> **THINK ABOUT**: $\\boldsymbol{u}\\boldsymbol{v}^T$ is a rank 1 matrix -\n",
    "> why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating Big Non-Square Matrices with Smaller????? Ones\n",
    "\n",
    "``` bash\n",
    ">> disp('from math-deep.pdf')\n",
    "from mhttps://www.cis.upenn.edu/~jean/math-deep.pdf\n",
    "\n",
    ">> A = [10 7 8 7;\n",
    "7 5 6 5;\n",
    "8 6 10 9;\n",
    "7 5 9 10]\n",
    "\n",
    "A =\n",
    "\n",
    "    10     7     8     7\n",
    "     7     5     6     5\n",
    "     8     6    10     9\n",
    "     7     5     9    10\n",
    "\n",
    ">> [V D] = eig(A)\n",
    "\n",
    "V =\n",
    "\n",
    "    0.5016   -0.3017    0.6149    0.5286\n",
    "   -0.8304    0.0933    0.3963    0.3803\n",
    "    0.2086    0.7603   -0.2716    0.5520\n",
    "   -0.1237   -0.5676   -0.6254    0.5209\n",
    "\n",
    "\n",
    "D =\n",
    "\n",
    "    0.0102         0         0         0\n",
    "         0    0.8431         0         0\n",
    "         0         0    3.8581         0\n",
    "         0         0         0   30.2887\n",
    "\n",
    ">> V*V'\n",
    "\n",
    "ans =\n",
    "\n",
    "    1.0000    0.0000   -0.0000   -0.0000\n",
    "    0.0000    1.0000    0.0000   -0.0000\n",
    "   -0.0000    0.0000    1.0000    0.0000\n",
    "   -0.0000   -0.0000    0.0000    1.0000\n",
    "\n",
    ">> A-V*D*V'\n",
    "\n",
    "ans =\n",
    "\n",
    "   1.0e-14 *\n",
    "\n",
    "   -0.3553   -0.2665   -0.5329   -0.1776\n",
    "   -0.2665         0         0   -0.0888\n",
    "   -0.5329         0         0   -0.1776\n",
    "         0         0   -0.1776         0\n",
    "\n",
    ">> L=zeros(4,4); L(4,4)=D(4,4)\n",
    "\n",
    "L =\n",
    "\n",
    "         0         0         0         0\n",
    "         0         0         0         0\n",
    "         0         0         0         0\n",
    "         0         0         0   30.2887\n",
    "\n",
    ">> (A-V*L*V')./A\n",
    "\n",
    "ans =\n",
    "\n",
    "    0.1538    0.1303   -0.1046   -0.1914\n",
    "    0.1303    0.1241   -0.0595   -0.2000\n",
    "   -0.1046   -0.0595    0.0772    0.0324\n",
    "   -0.1914   -0.2000    0.0324    0.1781\n",
    "\n",
    ">> L=zeros(4,4); L(4,4)=D(4,4); L(3,3)=D(3,3);\n",
    ">> (A-V*L*V')./A\n",
    "\n",
    "ans =\n",
    "\n",
    "    0.0079   -0.0040   -0.0240    0.0205\n",
    "   -0.0040    0.0029    0.0097   -0.0087\n",
    "   -0.0240    0.0097    0.0488   -0.0405\n",
    "    0.0205   -0.0087   -0.0405    0.0272\n",
    "```\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Sheet\n",
    "\n",
    "Look at review on CombinedNotes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outcomes\n",
    "\n",
    "After studying these notes you should be able to confidently:\n",
    "\n",
    "-   Add and subtract vectors and matrices of compatible dimension.\n",
    "\n",
    "-   Transpose a matrix, and recognise a square matrix.\n",
    "\n",
    "-   Compute the scalar product of vectors, and product of matrices when\n",
    "    they exist.\n",
    "\n",
    "-   \n",
    "\n",
    "CNTRL-OPTION-CLICK switch focus without raising\n",
    "\n",
    "Select finder and merge all windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS COPIED FROM VECTORS.IPYNB NEEDS UPDATING\n",
    "\n",
    "## Review\n",
    "\n",
    "We have just come a long way:\n",
    "\n",
    "- we reviewed the mathematical notion of a *vector*.\n",
    "- we saw how using `numpy` in `python` we could\n",
    "  - create vectors;\n",
    "  - add and subtract them, and multiply by a scalar;\n",
    "  - compute various vector norms and phoney norms.\n",
    "\n",
    "Furthermore\n",
    "\n",
    "- we saw how to access the *toy datasets* in `seaborn`.\n",
    "- how to work with `pandas` data frames.\n",
    "- how to extract data frame values.\n",
    "- how to represent a data point as a vector of features.\n",
    "\n",
    "We will be building extensively on these skills in the coming weeks.\n",
    "\n",
    "Taking raw data and manipulating it so that it is in a fomr suitable\n",
    "for analysis is often referred to as **Data Wrangling**. The `pandas`\n",
    "cheat sheet here <https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf> \n",
    "gives lots of examples of how to work with data frames.\n",
    "\n",
    "For now we finish off with a look at a few more of the *toy datasets*\n",
    "that `seaborn` provides. They are called *toy* because they are \n",
    "realistic enough to use when learning techniques and tools in\n",
    "data science, but also small enough to get answers in real time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "For ...:\n",
    "\n",
    "1. Do...\n",
    "2. Do...\n",
    "\n",
    "```\n",
    "1: code goes here\n",
    "2: code goes here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop Exercise\n",
    "\n",
    "Based originally on\n",
    "<https://stackoverflow.com/questions/8092920/sort-eigenvalues-and-associated-eigenvectors-after-using-numpy-linalg-eig-in-pyt>\n",
    "\n",
    "- How can we use code to re-order the eigenvalues in `w` so that their absolute values are in descending order?\n",
    "- How can we use that re-ordering to correctly re-order the eigenvectors that are in the columns of V?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = \n",
      " [[ 0.64520861 -0.72586798 -0.23837266]\n",
      " [-0.14839771  0.18699442 -0.97108764]\n",
      " [-0.74945578 -0.66192806 -0.01293327]]\n",
      "    w  =  [18.14414013 -0.43436748 -5.70977265]\n",
      "abs(w) =  [18.14414013  0.43436748  5.70977265]\n",
      "abs(w).argsort()           =  [1 2 0]\n",
      "np.flip( abs(w).argsort()) =  [0 2 1]\n",
      "abs(w).argsort()[::-1]     =  [0 2 1]\n",
      "indx =  [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "print('V = \\n', V)\n",
    "print('    w  = ', w)\n",
    "print('abs(w) = ', abs(w))\n",
    "\n",
    "print('abs(w).argsort()           = ', abs(w).argsort())\n",
    "print('np.flip( abs(w).argsort()) = ', np.flip( abs(w).argsort()))\n",
    "print('abs(w).argsort()[::-1]     = ', abs(w).argsort()[::-1])\n",
    "indx = np.flip( abs(w).argsort() )   \n",
    "print('indx = ', indx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  [18.14414013 -5.70977265 -0.43436748]\n",
      "V = \n",
      " [[ 0.64520861 -0.23837266 -0.72586798]\n",
      " [-0.14839771 -0.97108764  0.18699442]\n",
      " [-0.74945578 -0.01293327 -0.66192806]]\n"
     ]
    }
   ],
   "source": [
    "w = w[indx]\n",
    "V = V[:,indx]\n",
    "print('lambda = ', w)\n",
    "print('V = \\n', V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Re-visit the notes to find the eigen-decomposition of the matrix\n",
    "$\\boldsymbol{T}$ as given by,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{T} = \\left(\\begin{array}{rrr}\n",
    " 7 & -3 & -9 \\\\\n",
    "-3 & -5 &  2 \\\\\n",
    "-9 &  2 & 10\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Use code, as descibed above, to order the eigenvalues so that \n",
    "$\\vert\\lambda_1\\vert \\ge \\vert\\lambda_2\\vert \\ge \\vert\\lambda_3\\vert$ \n",
    "and determine the partial recontructions,\n",
    "\n",
    "- $\\boldsymbol{T}_1 = \\lambda_1\\boldsymbol{v}_1\\boldsymbol{v}_1^T$\n",
    "- $\\boldsymbol{T}_2 = \\lambda_1\\boldsymbol{v}_1\\boldsymbol{v}_1^T + \\lambda_2\\boldsymbol{v}_2\\boldsymbol{v}_2^T$\n",
    "\n",
    "Finally, check that $\\boldsymbol{T}_3 = \\boldsymbol{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 = \n",
      " [[ 7.55329941 -1.7372557  -8.77369555]\n",
      " [-1.7372557   0.39956808  2.0179463 ]\n",
      " [-8.77369555  2.0179463  10.19127264]]\n",
      "T2 = \n",
      " [[ 7.22886142 -3.05895812 -8.79129842]\n",
      " [-3.05895812 -4.98481151  1.94623536]\n",
      " [-8.79129842  1.94623536 10.19031757]]\n",
      "T-T3 = \n",
      " [[-4.44089210e-15  2.66453526e-15  7.10542736e-15]\n",
      " [ 2.66453526e-15  8.88178420e-16 -8.88178420e-16]\n",
      " [ 7.10542736e-15 -8.88178420e-16 -8.88178420e-15]]\n"
     ]
    }
   ],
   "source": [
    "T = np.array([[7,-3,-9],[-3,-5,2],[-9,2,10]])\n",
    "w, V = np.linalg.eig(T)\n",
    "indx = np.flip( abs(w).argsort() )   \n",
    "w = w[indx]\n",
    "V = V[:,indx]\n",
    "D=np.diag(w)\n",
    "T1 = D[0,0]*V[:,0:1]*V[:,0:1].T\n",
    "T2 = T1 + D[1,1]*V[:,1:2]*V[:,1:2].T\n",
    "T3 = T2 + D[2,2]*V[:,2:3]*V[:,2:3].T\n",
    "print('T1 = \\n', T1)\n",
    "print('T2 = \\n', T2)\n",
    "print('T-T3 = \\n', T-T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This point of view really suggests an approximation scheme.\n",
    "If $\\boldsymbol{A}$ is $n\\times n$ symmetric then\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} =\n",
    "\\sum_{k=1}^n\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "\\qquad\\text{ suggesting }\\qquad\n",
    "\\boldsymbol{A} \\approx\n",
    "\\sum_{k=1}^m\n",
    "\\lambda_k\\boldsymbol{v}_k\\boldsymbol{v}_k^T\n",
    "$$\n",
    "\n",
    "for $m < n$. We would want to sort the eigenvalues so that the\n",
    "most dominant ones come first in this sum, which is the same saying\n",
    "\n",
    "$$\n",
    "\\vert\\lambda_1\\vert \\ge\n",
    "\\vert\\lambda_2\\vert \\ge\n",
    "\\vert\\lambda_3\\vert \\ge  \\cdots\n",
    "$$\n",
    "\n",
    "And this is exactly what we did above.\n",
    "\n",
    "Let's see how that might work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  [ 8.21699057  7.         -1.21699057]\n",
      "E=\n",
      " [[2.24159712 1.12079856 3.48399703]\n",
      " [1.12079856 0.56039928 1.74199852]\n",
      " [3.48399703 1.74199852 5.41499417]]\n",
      "(A-E)/A [[ 0.25280096  1.56039928  0.12900074]\n",
      " [ 1.56039928  0.90660012  0.12900074]\n",
      " [ 0.12900074  0.12900074 -0.08299883]]\n",
      "max{ (A-E)/A } 1.5603992792021621\n",
      "E=\n",
      " [[ 3.64159712 -1.67920144  3.48399703]\n",
      " [-1.67920144  6.16039928  1.74199852]\n",
      " [ 3.48399703  1.74199852  5.41499417]]\n",
      "(A-E)/A [[-0.21386571  0.16039928  0.12900074]\n",
      " [ 0.16039928 -0.02673321  0.12900074]\n",
      " [ 0.12900074  0.12900074 -0.08299883]]\n",
      "max{ (A-E)/A } 0.16039927920216146\n",
      "E=\n",
      " [[ 3. -2.  4.]\n",
      " [-2.  6.  2.]\n",
      " [ 4.  2.  5.]]\n",
      "(A-E)/A [[-1.62832710e-15 -1.33226763e-15 -8.88178420e-16]\n",
      " [-1.33226763e-15  4.44089210e-16  2.22044605e-16]\n",
      " [-8.88178420e-16  2.22044605e-16  1.77635684e-16]]\n",
      "max{ (A-E)/A } 4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3,-2,4],[-2,6,2],[4,2,5]])\n",
    "w, V = np.linalg.eig(A)\n",
    "indx = np.flip( abs(w).argsort() )   \n",
    "w = w[indx]\n",
    "V = V[:,indx]\n",
    "D=np.diag(w)\n",
    "print('w = ', w)\n",
    "E = np.zeros(A.shape)\n",
    "for i in range(0,3):\n",
    "    E = E + D[i,i]*np.matmul(V[:,i:i+1],V[:,i:i+1].T)\n",
    "    print('E=\\n',E)\n",
    "    print('(A-E)/A', (A-E)/A)\n",
    "    print('max{ (A-E)/A }', np.max( (A-E)/A) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Notes\n",
    "\n",
    "This originated from\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n",
    "\n",
    "These lines create a back up of the notebook. They can be ignored.\n",
    "\n",
    "At some point this is better as a bash script outside of the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 7_decomp.ipynb to html\n",
      "[NbConvertApp] Writing 661014 bytes to 7_decomp.html\n",
      "[NbConvertApp] Converting notebook 7_decomp.ipynb to pdf\n",
      "[NbConvertApp] Writing 81339 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 119625 bytes to 7_decomp.pdf\n",
      "[NbConvertApp] Converting notebook 7_decomp.ipynb to script\n",
      "[NbConvertApp] Writing 34162 bytes to 7_decomp.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "NBROOTNAME='7_decomp'\n",
    "OUTPUTTING=1\n",
    "\n",
    "if [ $OUTPUTTING -eq 1 ]; then\n",
    "  jupyter nbconvert --to html $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.html ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.html\n",
    "  mv -f $NBROOTNAME.html ./formats/html/\n",
    "\n",
    "  jupyter nbconvert --to pdf $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.pdf ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pdf\n",
    "  mv -f $NBROOTNAME.pdf ./formats/pdf/\n",
    "\n",
    "  jupyter nbconvert --to script $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.py ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.py\n",
    "  mv -f $NBROOTNAME.py ./formats/py/\n",
    "else\n",
    "  echo 'Not Generating html, pdf and py output versions'\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
