{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MA5634: Fundamentals of Machine Learning\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "Simon Shaw\n",
    "<https://www.brunel.ac.uk/people/simon-shaw>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses python</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td> \n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What this is about:\n",
    "\n",
    "You will be introduced to ...\n",
    "\n",
    "- fundamental techniques used in data science, like:\n",
    "    - $k$-NN: $k$-Nearest Neighbours;\n",
    "    - data reduction with SVD and PCA;\n",
    "    - linear and polynomial regression;\n",
    "    - perceptrons and support vector machines;\n",
    "    - neural networks and deep learning.\n",
    "- essential mathematical concepts: *just enough: progress at pace*\n",
    "    - you are **not expected to be a mathematician** ...\n",
    "    - ... but you will be expected to either recall or learn basic facts and techniques in \n",
    "        - vectors, matrices, and differential calculus\n",
    "- essential `python` programming: *just enough: progress at pace*\n",
    "    - you are **not expected to be a computer scientist** ...\n",
    "    - ... but `python` will be introduced and used as a tool\n",
    "        - only the necessary `python` syntax, tools and techniques will be taught\n",
    "        - our emphasis will be on *doing* rather than *proving*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Assessment\n",
    "\n",
    "- 40% coursework (details to follow in a few weeks)\n",
    "- 60% examination (revision and reflection time will be allocated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Study Guide\n",
    "\n",
    "The Quality Assurance Agency for Higher Education\n",
    "(QAA, <https://www.qaa.ac.uk>) defines one academic\n",
    "credit as nominally equal to 10 hours of\n",
    "study (see <https://www.qaa.ac.uk/docs/qaa/quality-code/higher-education-credit-framework-for-england.pdf>).\n",
    "\n",
    "Therefore, this 15 credit block requires nominally 150 hours of your time.\n",
    "Although every one of us is different and may choose to spend our time in different ways,\n",
    "the following sketch of these 150 hours is fairly accurate.\n",
    "\n",
    "There will be $33$ hours spent on two lectures plus one seminar/lab in each of\n",
    "eleven weeks. There will be a two hour exam, to which you could assign $25$ hours of\n",
    "preparation/revision time. This accounts for $33+2+25 = 60$ hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In addition there is assignment which you could allocate $20$ hours to, making up\n",
    "to $80$ hours. This leaves $70$ of the $150$ hours over. In each of $10$ \n",
    "weeks of term there will be a requirement to engage in set tasks and problems, and\n",
    "to read sections of set books and sources in order to strengthen your understanding\n",
    "of imparted material as well as to prepare you for the next topics. These $70$ \n",
    "hours average out to $7$ hours per week over those $10$ weeks.\n",
    "\n",
    "Note that as a full-time equivalent student you study a $4\\times 15 = 60$ credit week.\n",
    "Using the figures above you can think of this as $4\\times 3 = 12$ contact hours plus\n",
    "$4 \\times 7 = 28$ private study hours per week. This is a $40$ hour week. \n",
    "\n",
    "Note that engaging at this level does not guarantee any outcome, whether that be a \n",
    "bare pass or an A grade. It is a guideline only. If despite engaging at this level\n",
    "you are struggling to progress and achieve in the module then seek help and advice.\n",
    "\n",
    "Further, these '$40$ hours' have to be high quality inquisitive engagement. \n",
    "Writing and re-writing notes, procrastinating, and looking at but not \n",
    "engaging with learning materials don't really count. You'll know when you're \n",
    "actually **working** - you'll feel it. Have a read of this\n",
    "<https://en.wikipedia.org/wiki/Flow_(psychology)> and make learning a daily rewarding habit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key Concepts: Glossary of Relevant Terms\n",
    "\n",
    "The first few of these are debateable, evolving and subject to change and\n",
    "interpretation. It's worth searching and reading for yourself.\n",
    "These are a fast growing areas.\n",
    "\n",
    "\n",
    "#### Data Science\n",
    "\n",
    "A blend of mathematics, computer science and statistics brought to bear with some form of domain expertise.\n",
    "\n",
    "#### Data Analytics\n",
    "\n",
    "Systematic computational analysis of data, used typically to discover value and insights.\n",
    "\n",
    "#### Data Engineering\n",
    "\n",
    "The stewardship, cleaning, warehousing and preparation of data to support its pipelining to its\n",
    "exploitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Artificial Intelligence\n",
    "\n",
    "The development and deployment of digital systems that can effectively substitute for humans in \n",
    "tasks beyond the routine application of fixed rules. When you talk to your home assistant, your\n",
    "phone, or your satellite TV receiver, or your car, or your laptop, and so on, it has no idea\n",
    "what you are going to say. It doesn't have a bank of pre-answered questions, but instead it\n",
    "responds dynamically to what it hears. It has been trained on data, and it has learned how to\n",
    "respond. Incidentally, how do you think these systems even understand what you said? As a child,\n",
    "it took you months to begin to understand human speech..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Machine Learning\n",
    "\n",
    "The development and deployment of algorithms that are able to learn from data without explicit instructions,\n",
    "and then analyze, predict, or otherwise draw inferences, from unseen data. These algorithms would typically\n",
    "be expected to add measurable value by their performance.\n",
    "\n",
    "> *Consider for example an algorithm that predicted __tails__ for every coin flip. It's\n",
    "> right half the time* - but there's no value in that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Learning\n",
    "\n",
    "Machine learning models do not have intrinsic knowledge but instead learn from data.\n",
    "Typically a data set comprises a list of items each of which has one or more \n",
    "*features* which correspond to a *label*. We'll see some examples of this below.\n",
    "\n",
    "We think of the features as being inputs to the machine learning model, and the label\n",
    "as being the output. Typically we want to be able to feed in new features, and have\n",
    "the model predict the label.\n",
    "\n",
    "To do this we need a **training data set** so that the model can learn how to map the\n",
    "features to the label: the *input to the output*.\n",
    "\n",
    "There are three basic learning paradigms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Supervised Learning**:\n",
    "Here the data is labelled. This means that for a given set of features, or inputs, we also know\n",
    "their labels, or outputs. Examples of this are where...\n",
    "  - We could have a list of features of insured drivers, such as age, time since they passed\n",
    "  their driving test, type of car, locality, and along with those features a monetary \n",
    "  value on their accident claim. The task would be to learn how much of an insurance premium\n",
    "  to charge to a new customer once those features have been determined.\n",
    "  - We might have a bank of images of handwritten digits, and for each image we know what \n",
    "  digit is represented. The MNIST database of handwritten digits, see\n",
    "  <http://yann.lecun.com/exdb/mnist/> or <https://en.wikipedia.org/wiki/MNIST_database>\n",
    "  for example, is a well known example of this. The task is to learn how to predict \n",
    "  what digit is captured by a new image. This could be used in ANPR systems for example,\n",
    "  <https://en.wikipedia.org/wiki/Automatic_number-plate_recognition>.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Unsupervised Learning**:\n",
    "This is where we only know the features and we want to cluster the data in such a way \n",
    "that a set of similar features can be assiociated with some common characteristic (the label).\n",
    "  - This can be used on data where the anlayst doesn't initially know what they are looking\n",
    "  for. For example, a retailer might have a mass of data of customer age, locale, average spend,\n",
    "  types of purchased item, time of day of purchase, day of week of purchase, time of year etc.\n",
    "  What characteristics can be used to group these customers? How can advertising be targetted? \n",
    "  - principal component analysis seeks to re-orient data so that its dominant statistical\n",
    "  properties are revealed. We'll see this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Reinforcement Learning**:\n",
    "This seeks to strike a balance between the two above. There are no labels, but instead, as time\n",
    "progresses the learning algorithm has a *reward* variable which is increased when an action it\n",
    "has learned has resulted in a measurable benefit. Over time the algorithm develops a policy to\n",
    "inform its actions.\n",
    "\n",
    "This last is a major topic and will not be covered in these lectures. We will see examples of\n",
    "the first two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Regression and Classification\n",
    "\n",
    "Our algorithms will be developed to perform one of the following tasks:\n",
    "\n",
    "- **Regression:** here the output, the label, can take any value in a continuous set. For example,\n",
    "  the height of a tree, given local climate, soil type, genus, age since planting, could be \n",
    "  considered to be any non-negative real number (although not with equal probability). \n",
    "\n",
    "- **Classification:** in this case the label will be deemed to be one of a certain class. For \n",
    "  example, in the handwritten digits example above, the output will be one of the digits\n",
    "  $\\{0,1,2,3,\\ldots,9\\}$.\n",
    "\n",
    "Some of the algorithms we study will be able to perform both the regression and clustering tasks,\n",
    "although we wont always delve deeply into both capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading List\n",
    "\n",
    "For the data science, our main sources of information are as follows:\n",
    "    \n",
    "- MML: Mathematics for Machine Learning, by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong.\n",
    "  Cambridge University Press. <https://mml-book.github.io>.\n",
    "- MLFCES: Machine Learning: A First Course for Engineers and Scientists, by Andreas Lindholm,\n",
    "  Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön. Cambridge University Press. \n",
    "  <http://smlbook.org>.\n",
    "- FCLA: A First Course in Linear Algebra, by Ken Kuttler, \n",
    "  <https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)>\n",
    "- AP: Applied Probability, by Paul Pfeiffer\n",
    "  <https://stats.libretexts.org/Bookshelves/Probability_Theory/Applied_Probability_(Pfeiffer)>\n",
    "- IPDS: Introduction to Probability for Data Science, by Stanley H. Chan,\n",
    "  <https://probability4datascience.com>\n",
    "- SVMS: Support Vector Machines Succinctly, by Alexandre Kowalczyk,\n",
    "  <https://www.syncfusion.com/succinctly-free-ebooks/support-vector-machines-succinctly>\n",
    "- VMLS: Introduction to Applied Linear Algebra - Vectors, Matrices, and Least Squares,\n",
    "  by Stephen Boyd and Lieven Vandenberghe,\n",
    "  <https://web.stanford.edu/~boyd/vmls/>\n",
    " \n",
    "\n",
    "All of the above can be accessed legally and without cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are also these useful references for coding:\n",
    "\n",
    "- PT: `python`: <https://docs.python.org/3/tutorial>\n",
    "- NP: `numpy`: <https://numpy.org/doc/stable/user/quickstart.html>\n",
    "- MPL: `matplotlib`: <https://matplotlib.org>\n",
    "\n",
    "The capitalized abbreviations will be used throughout to refer to these sources. For example, we could\n",
    "say *See [MLFCES, Chap 2, Sec. 1] for more discussion of __Supervised Learning__*. This would\n",
    "just be a quick way of saying\n",
    "\n",
    "> Look in Section 1, of Chapter 2, of Machine Learning: A First Course for Engineers and\n",
    "> Scientists, by Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön,\n",
    "> for more discussion of supervised learning. \n",
    "\n",
    "There will be other sources shared as we go along. For now these will get us a long way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coding: `python` and some data sets\n",
    "\n",
    "For each of our main topics we will see some example data, discuss a means of working with it,\n",
    "and then implement those means in code. We will develop enough theory so as to understand how\n",
    "the codes work, but our main focus will be the intution behind the method, and the effective\n",
    "problem solving using code.\n",
    "\n",
    "We choose `python` because its use in both the commercial and academic data science\n",
    "arena seems to be pre-eminent.\n",
    "\n",
    "The data science techniques and algorithms we will study, and the supporting technology\n",
    "like graphics and number crunching, are implemented in well-known and well-documented\n",
    "`python` libraries. These are the main ones we will use:\n",
    "\n",
    "- `matplotlib`: used to create visualizations, plotting 2D graphs in particular.\n",
    "- `numpy`: this is *numerical python*, it is used for array processing which for us \n",
    "   will usually mean the numerical calculations involving vectors and matrices.\n",
    "- `scikit-learn`: a set of well documented and easy to use tools for predictive data analysis.\n",
    "- `pandas`: a data analysis tool, used for the storing and manipulation of data.\n",
    "- `seaborn`: a data visualization library for attractive and informative statistical graphics. \n",
    "\n",
    "There will be others, but these are the main ones. Let's look at some examples of how to use these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binder, Anaconda, Jupyter - a first look at some data\n",
    "\n",
    "Eventually we will use the anaconda distribution to access `python` and the libraries\n",
    "we need. The coding itself will be carried out in a Jupyter notebook. We'll go through this\n",
    "in an early lab session. We'll start though with Binder: click here:\n",
    "\n",
    "<https://mybinder.org/v2/gh/variationalform/FML.git/HEAD>\n",
    "\n",
    "Let's see some code and some data. In the following cell we import `seaborn` and look at\n",
    "the names of the built in data sets. The `seaborn` library, <https://seaborn.pydata.org>,\n",
    "is designed for data visualization. It uses `matplotlib`, <https://matplotlib.org>,\n",
    "which is a graphics library for `python`.\n",
    "\n",
    "If you want to dig deeper, you can look at\n",
    "<https://blog.enterprisedna.co/how-to-load-sample-datasets-in-python/>\n",
    "and <https://github.com/mwaskom/seaborn-data> for the background - but you don't need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# we can now refer to the seaborn library functions using 'sns'\n",
    "# note that you can use another character string - but 'sns' is standard.\n",
    "\n",
    "# note that # is used to write 'comments'\n",
    "# Now let's get the names of the built-in data sets.\n",
    "sns.get_dataset_names()\n",
    "\n",
    "# type SHIFT=RETURN to execute the highlighted (active) cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `taxis` data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# let's take a look at 'taxis'\n",
    "dft = sns.load_dataset('taxis')\n",
    "# this just plots the first few lines of the data\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this will plot the last few lines... There are 6433 records (Why?)\n",
    "dft.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What we are seeing here is a **data frame**. It is furnished by the `pandas`\n",
    "library: <https://pandas.pydata.org> which is used by the `seaborn` library \n",
    "to store its example data sets.\n",
    "\n",
    "Each row of the data frame corresponds to a single **data point**, which we \n",
    "could also call an `observation` or `measurement` (depending on context).\n",
    "\n",
    "Each column (except the left-most) corresponds to a **feature** of the data \n",
    "point. The first column is just an index giving the row number. Note that this\n",
    "index starts at zero - so, for example, the third row will be labelled/indexed\n",
    "as $2$. Be careful of this - it can be confusing.\n",
    "\n",
    "In this, the variable dft is a pandas data frame: dft = 'data frame taxis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# let's print the data frame...\n",
    "print(dft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualization\n",
    "\n",
    "Rows and rows of numbers aren't that helpful. \n",
    "\n",
    "seaborn makes visualization easy - here is a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dft, x=\"distance\", y=\"fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **THINK ABOUT**: it looks like fare is roughly proportional to distance.\n",
    "> But what could cause the outliers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# here's another example\n",
    "sns.scatterplot(data=dft, x=\"pickup_borough\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# is the tip proportional to the fare?\n",
    "sns.scatterplot(data=dft, x=\"fare\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# is the tip proportional to the distance?\n",
    "sns.scatterplot(data=dft, x=\"distance\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `tips` data set\n",
    "\n",
    "Let's look now at the `tips` data set. Along the way we'll see a few more\n",
    "ways we can use the data frame object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# load the data - dft: data frame tips\n",
    "# note that this overwrites the previous 'value/meaning' of dft\n",
    "dft = sns.load_dataset('tips')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An extensive list of data frame methods/functions can be found here: \n",
    "<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame>\n",
    "Let's look at some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(dft.info)\n",
    "print('The shape of the data frame is: ', dft.shape)\n",
    "print('The size of the data frame is: ', dft.size)\n",
    "print('Note that 244*7 =', 244*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Visualization\n",
    "\n",
    "Again, numbers aren't always that helpful. Plots often give us more insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dft.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dft, x=\"total_bill\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Statistics and Probability\n",
    "\n",
    "You're assumed to be familiar with basic terms and concepts in these areas,\n",
    "but we will revise and review those that we need later.\n",
    "\n",
    "We can get some basic stats for our data set with the `describe()` method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# here are some descriptive statistics\n",
    "dft.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `anscombe` data set\n",
    "\n",
    "This is pretty famous. There are four sets of 11 coordinate pairs.\n",
    "When plotted they look completely different. \n",
    "But they have the same summary statistics (at least the common ones).\n",
    "\n",
    "See <https://en.wikipedia.org/wiki/Anscombe%27s_quartet>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Julia-anscombe-plot-1.png\" style=\"height:300px\"/>\n",
    "\n",
    "Image Credit: `https://upload.wikimedia.org/wikipedia/commons/7/7e/Julia-anscombe-plot-1.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's load the data set and take a look at it - we can look at the head and tail of the\n",
    "table just as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa = sns.load_dataset('anscombe')\n",
    "# look at how we get an apostrophe in the string...\n",
    "print(\"The size of Anscombe's data set is:\", dfa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It looks like the four data sets are in the `dataset` column. How can we extract them as separate items? \n",
    "\n",
    "Well, one way is to print the whole dataset and see which rows correspond to each dataset. Like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From this and the `head` and `tail` output above we can infer that there are four\n",
    "data sets: I, II, III and IV. They each contain $11$ pairs $(x,y)$.\n",
    "\n",
    "- The first set occupies rows $0,1,2,\\ldots,10$\n",
    "- The second set occupies rows $11,12,\\ldots,21$\n",
    "- The third set occupies rows $22,23,\\ldots,32$\n",
    "- The fourth set occupies rows $33,34,\\ldots,43$\n",
    "\n",
    "However, this kind of technique is not going to be useful if we have a data set \n",
    "with millions of data points (rows). We certainly wont want to print them all \n",
    "like we did above.\n",
    "\n",
    "Is there another way to determine the number of distinct feature values in a\n",
    "given column of the data frame?\n",
    "\n",
    "Fortunately, yes. We want to know how many different values the `dataset` column \n",
    "has. We can do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfa.dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can count the number of different ones automatically too, by asking\n",
    "for the `shape` of the returned value. Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa.dataset.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This tell us that there are 4 items - as expected.\n",
    "Don't worry too much about it saying `(4,)` rather that just `4`. \n",
    "We'll come to that later when we discuss `numpy`\n",
    "(Numerical python: <https://numpy.org>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, we want to extract each of the four datasets as separate data sets so we can work\n",
    "with them. We can do that by using `loc` to get the row-wise locations where each \n",
    "value of the `dataset` feature is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, using the hints here\n",
    "<https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values>,\n",
    "to get the data for the sub-data-set `I` we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa.loc[dfa['dataset'] == 'I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have this subset of data we can examine it - with a scatter plot \n",
    "for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa.loc[dfa['dataset'] == 'I'], x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To really work properly with each subset we should extract them and give each\n",
    "of them a name that is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfa1 = dfa.loc[dfa['dataset'] == 'I']\n",
    "dfa2 = dfa.loc[dfa['dataset'] == 'II']\n",
    "dfa3 = dfa.loc[dfa['dataset'] == 'III']\n",
    "dfa4 = dfa.loc[dfa['dataset'] == 'IV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now let's look at each of the four data sets in a scatter plot,\n",
    "and use the `describe` method to examine the summary statistics.\n",
    "\n",
    "The outcome is quite surprising..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa1, x=\"x\", y=\"y\")\n",
    "dfa1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa2, x=\"x\", y=\"y\")\n",
    "dfa2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa3, x=\"x\", y=\"y\")\n",
    "dfa3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa4, x=\"x\", y=\"y\")\n",
    "dfa4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "For the `taxis` data set:\n",
    "\n",
    "1. Produce a scatterplot of \"dropoff_borough\" vs. \"tip\"\n",
    "2. Plot the dependence of fare on distance. \n",
    "\n",
    "```\n",
    "1: sns.scatterplot(data=ds, x=\"dropoff_borough\", y=\"tip\")\n",
    "2: sns.scatterplot(data=ds, x=\"distance\", y=\"tip\")\n",
    "```\n",
    "\n",
    "For the `tips` data set:\n",
    "\n",
    "1. What is the standard deviation of the tips?\n",
    "2. Plot the scatter of tip against the total bill\n",
    "3. Plot the scatter of total bill against day\n",
    "4. Plot the scatter of tip against gender\n",
    "\n",
    "```\n",
    "1: ds.describe()\n",
    "2: sns.scatterplot(data=ds, x=\"total_bill\", y=\"tip\")\n",
    "3: sns.scatterplot(data=ds, x=\"day\", y=\"total_bill\")\n",
    "4: sns.scatterplot(data=ds, x=\"sex\", y=\"tip\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Technical Notes, Production and Archiving\n",
    "\n",
    "Ignore the material below. What follows is not relevant to the material being taught."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Production Workflow\n",
    "\n",
    "- Finalise the notebook material above\n",
    "- Set `OUTPUTTING=1` below\n",
    "- Clear and fresh run of entire notebook\n",
    "- Create html slide show:\n",
    "  - `jupyter nbconvert --to slides 1_intro.ipynb `\n",
    "- Clear all cell output\n",
    "- Set `OUTPUTTING=0` below\n",
    "- Save\n",
    "- git add, commit and push to FML\n",
    "- copy PDF, HTML etc to web site\n",
    "  - git add, commit and push\n",
    "- rebuild binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Ignore this - it is done in 2_vectors\n",
    "\n",
    "For the Anscombe data set:\n",
    "\n",
    "1. Which of the summary statistics for $x$ are the same or similar for each subset?\n",
    "1. Which of the summary statistics for $y$ are the same or similar for each subset?\n",
    "\n",
    "\n",
    "Look at the `diamonds` data set \n",
    "\n",
    "1. How many diamonds are listed there? How many attributes does each have?\n",
    "2. Scatter plot price against carat.\n",
    "\n",
    "```\n",
    "1: ds = sns.load_dataset('diamonds'); ds.shape: 53940 and 10\n",
    "2: sns.scatterplot(data=ds, x=\"carat\", y=\"price\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some of this originated from\n",
    "\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n",
    "\n",
    "These lines create a back up of the notebook. They can be ignored.\n",
    "\n",
    "At some point this is better as a bash script outside of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "NBROOTNAME='1_intro'\n",
    "OUTPUTTING=0\n",
    "\n",
    "if [ $OUTPUTTING -eq 1 ]; then\n",
    "  jupyter nbconvert --to html $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.html ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.html\n",
    "  mv -f $NBROOTNAME.html ./formats/html/\n",
    "\n",
    "  jupyter nbconvert --to pdf $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.pdf ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pdf\n",
    "  mv -f $NBROOTNAME.pdf ./formats/pdf/\n",
    "\n",
    "  jupyter nbconvert --to script $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.py ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.py\n",
    "  mv -f $NBROOTNAME.py ./formats/py/\n",
    "else\n",
    "  echo 'Not Generating html, pdf and py output versions'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
