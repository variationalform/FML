{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worksheet E\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "Simon Shaw\n",
    "<https://www.brunel.ac.uk/people/simon-shaw>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses python</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td> \n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What this is about:\n",
    "\n",
    "This worksheet is based on the material in the notebooks\n",
    "\n",
    "- probstat\n",
    "- regress\n",
    "- svm\n",
    "- percep\n",
    "- pca\n",
    "\n",
    "Note that while the 'lecture' notebooks are prefixed with `1_`, `2_` and so on,\n",
    "to indicate the order in which they should be studied, the worksheets are prefixed\n",
    "with `A_`, `B_`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "A fair dice is thrown: What is the probability that\n",
    "\n",
    "- it falls on a six?\n",
    "- it falls on an even number?\n",
    "- it falls on an odd number greater than 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2 \n",
    "\n",
    "The defence counsel in the following case has called you as an\n",
    "expert witness.\n",
    "\n",
    "*A woman is on trial for murder. There is no evidence against \n",
    "her except for a lab-reported DNA match between her and a\n",
    "scene-of-crime sample. The prosecution have correctly stated that the \n",
    "theoretical probability of a match between two randomly selected \n",
    "people is one in a million, and thereby conclude that the \n",
    "probability the defendant is innocent is $10^{-6}$.*\n",
    "\n",
    "*Your legal team have learned that, while the lab never fails to \n",
    "identify a true match, it falsely reports a match once in\n",
    "every $100,000$ tests (due, for example, to technology \n",
    "limitations, human error, ...). The court is also aware that\n",
    "there are around two million other women who fit the criminal profile\n",
    "and, therefore, could have committed the crime.*\n",
    "\n",
    "What do you advise the defense counsel?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "When studying regression we defined the notion of cost as, for example, total squared error, TSE, with **regularization**:\n",
    "\n",
    "$$\n",
    "\\mathcal{E}(\\boldsymbol{\\theta})\n",
    "= \n",
    "\\Vert\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\Vert_2^2\n",
    "+\\alpha\\Vert\\boldsymbol{\\theta}\\Vert_p^p\n",
    "$$\n",
    "\n",
    "for $p=2$ (ridge) or $p=1$ (LASSO). This regularization term is often\n",
    "referred to as a **penalty term** in the sense that it **penalises** large\n",
    "coeffcients.\n",
    "\n",
    "Given that we are trying to minimise cost it is clear that with $\\alpha>0$ \n",
    "we will also be trying to minimize $\\alpha\\Vert\\boldsymbol{\\theta}\\Vert_p^p$\n",
    "which, in turn, tends to introduce small coefficients. \n",
    "\n",
    "More than that though, the choice $p=1$ may introduce sparsity into the \n",
    "coefficent vector. This is a form of **feature selection**.\n",
    "\n",
    "We can see why the $\\ell_1$ norm seems to promote sparsity by borrowing\n",
    "from the discussion here:\n",
    "<https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Define the vector $\\boldsymbol{v}=(1,\\epsilon)^T$ for some small\n",
    "$\\epsilon > 0$ and show that \n",
    "$\\Vert\\boldsymbol{v}\\Vert_1 = 1+\\epsilon$ and\n",
    "$\\Vert\\boldsymbol{v}\\Vert_2^2=1+\\epsilon^2$.\n",
    "\n",
    "2. Assume that regularization reduces the first coefficent by $\\delta$\n",
    "(with $0<\\delta <\\epsilon <1$)\n",
    "so that $\\boldsymbol{v}$ becomes $\\boldsymbol{v}=(1-\\delta,\\epsilon)^T$.\n",
    "Show that now,\n",
    "\n",
    "$$\n",
    "\\Vert\\boldsymbol{v}\\Vert_1 = 1-\\delta+\\epsilon\n",
    "\\qquad\\text{and}\\qquad\n",
    "\\Vert\\boldsymbol{v}\\Vert_2^2=1-2\\delta+\\delta^2+\\epsilon^2.\n",
    "$$\n",
    "\n",
    "3. Now, assume instead that regularization reduces the second coefficent\n",
    "by $\\delta$ (with $0<\\delta <\\epsilon < 1$)\n",
    "so that $\\boldsymbol{v}$ becomes $\\boldsymbol{v}=(1,\\epsilon-\\delta)^T$.\n",
    "Show that now,\n",
    "\n",
    "$$\n",
    "\\Vert\\boldsymbol{v}\\Vert_1 = 1+\\epsilon-\\delta\n",
    "\\qquad\\text{and}\\qquad\n",
    "\\Vert\\boldsymbol{v}\\Vert_2^2=1+\\epsilon^2-2\\epsilon\\delta+\\delta^2.\n",
    "$$\n",
    "\n",
    "4. Is the reduction in norm the same in both cases for the $\\ell_1$ norm?\n",
    "\n",
    "5. Is the reduction in norm the same in both cases for the $\\ell_2$ norm?\n",
    "If not, for which is the reduction largest?\n",
    "\n",
    "6. Explain what the author on the website (as above) means when s/he says \n",
    "\n",
    ">*it's not so much that $\\ell_1$ penalties encourage sparsity, but that\n",
    ">$\\ell_2$ penalties in some sense discourage sparsity...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Find the equation of the straight line that passes between the points\n",
    "$\\boldsymbol{q} = (q_1,q_2)$ and $\\boldsymbol{r} = (r_1,r_2)$ in the $(x_1, x_2)$ plane.\n",
    "\n",
    "The minimum distance between each point and the line should be the same.\n",
    "\n",
    "Find the general form of the equation of the line. And give the specific form in the\n",
    "case $\\boldsymbol{q} = (5,1)$ and $\\boldsymbol{r} = (2,3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Write the straight line equation $x_2 = x_1 + 1$ in the form \n",
    "$\\boldsymbol{w}\\cdot\\boldsymbol{x}=\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6\n",
    "\n",
    "Find the shortest distance from the point $Q$ at coordinates\n",
    "$(2,1)$ to the line $\\boldsymbol{w}\\cdot\\boldsymbol{x}=\\phi$\n",
    "with $\\boldsymbol{w}=(-1,1)^T$ and $\\phi=1$.\n",
    "\n",
    "Caluclate this by hand, and use python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "1. Use `x1 = np.arange(-2,3,1)` to create a one dimentsional grid in the\n",
    "`x1` direction. Print `x1` to understand what is happening.\n",
    "\n",
    "2. Use `x2 = np.arange(-2,3,1)` to create a one dimentsional grid in the\n",
    "`x2` direction. Print `x2` to understand what is happening.\n",
    "\n",
    "3. Use these lines of code to create 2D grids giving `x1` coordinates \n",
    "and `x2` coordinates in each variable:\n",
    "\n",
    "```\n",
    "import numpy.matlib\n",
    "N = x1.shape[0]\n",
    "X1grid = np.matlib.repmat(x1,N,1)\n",
    "X2grid = np.matlib.repmat(x2,N,1).T\n",
    "```\n",
    "Again, print your results to understand what is happening. Can you see why\n",
    "the `.T` is used for transpose?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Continuing from the last question, use this code in a new cell to\n",
    "evaluate the function $y=x_1+x_2$ on the 2D grid. Use the \n",
    "`indx` variable to plot the function in blue when $y<0$ and in\n",
    "red otherwise. Print out $y$ and `indx` so you can see exactly \n",
    "what is going on.\n",
    "\n",
    "```\n",
    "y = X1grid + X2grid\n",
    "print(y)\n",
    "indx = y < 0\n",
    "print(indx)\n",
    "plt.scatter(X1grid[indx],X2grid[indx], color='blue')\n",
    "plt.scatter(X1grid[~indx],X2grid[~indx], color='red')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 9\n",
    "\n",
    "Replace `plt.scatter` with `plt.plot` in the above (in a new cell). What happens?\n",
    "\n",
    "Can you solve this by replacing `color='blue'` with `.b` (similarly with `.r`)?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 10\n",
    "\n",
    "Flatten the grids and the index with\n",
    "\n",
    "```\n",
    "X1f = X1grid.flatten()\n",
    "X2f = X2grid.flatten()\n",
    "indxf = indx.flatten()\n",
    "```\n",
    "\n",
    "Print out these new quantites - what has happened?\n",
    "\n",
    "Use these flattened arrays with `plt.scatter` and `plt.plot` as above.\n",
    "Are the plots the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 11\n",
    "\n",
    "Design a two-input, one-output perceptron, with a Heaviside activation \n",
    "function, that has decision boundary $4 - 7x_1 + 3x_2=0$.\n",
    "\n",
    "Evaluate the output of the perceptron for the inputs \n",
    "$\\boldsymbol{x} = (-4,3)^T$ and\n",
    "$\\boldsymbol{x} = (6,2)^T$.\n",
    "\n",
    "Plot this decision boundary with a solid black line over \n",
    "$0.5 \\le x_1 \\le 1.5$.\n",
    "\n",
    "Also, illustrate this decision boundary for \n",
    "$0\\le x_1, x_2 \\le 2$ using a background grid of points\n",
    "(as above) with grid spacing 0.1 and two colours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 12\n",
    "\n",
    "Design a two-input, two-output Heaviside-activated\n",
    "neural network that has decision boundaries\n",
    "$5x_1 + 3x_2 + 6=0$ and $4x_1 + 7x_2 + 3=0$.\n",
    "\n",
    "Evaluate the output of the perceptron for the inputs \n",
    "$\\boldsymbol{x} = (-4,3)^T$, $\\boldsymbol{x} = (6,2)^T$, $\\boldsymbol{x} = (-6,2)^T$\n",
    "and $\\boldsymbol{x} = (6,-6)^T$.\n",
    "\n",
    "Plot these decision boundaries with dotted black lines over \n",
    "$-7 \\le x_1 \\le 4$.\n",
    "\n",
    "Also, illustrate these decision boundaries for \n",
    "$-10\\le x_1, x_2 \\le 10$ using a background grid of points\n",
    "(as above) with grid spacing 1 and four colours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 13\n",
    "\n",
    "A binary classifier gives the following predicted outputs on the test set:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>test label</th>\n",
    "    <td>pass</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>predicted</th>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "    <td>pass</td>\n",
    "    <td>pass</td>\n",
    "    <td>fail</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Create the confusion matrix first by hand, and then using code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 14\n",
    "\n",
    "Suppose you have these data points:\n",
    "$(\\boldsymbol{x}_1, \\boldsymbol{x}_2) = (3,3),\\ (-3,-3)$ corresponding to\n",
    "the features $\\boldsymbol{x}_1$ and $\\boldsymbol{x}_2$.\n",
    "\n",
    "Perform a principal component analysis (PCA). Before actually computing any \n",
    "results, think about what you are expecting to find. \n",
    "\n",
    "Suppose $(3,3)$ is removed but two more points are added: $(1,2),\\ (2,1)$.\n",
    "Repeat the PCA. What do you find now?\n",
    "\n",
    "In each case, determine the coordinates of these points in the principal \n",
    "component system. Discuss the empirical variance in the data sets and the relevance of\n",
    "the eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline solutions\n",
    "\n",
    "As usual - try the above before looking at these..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 1\n",
    "\n",
    "Here $\\Omega = \\{1,2,3,4,5,6\\}$ and $\\mathcal{E}$ has $2^{\\vert\\Omega\\vert}=2^6$ elements.\n",
    "\n",
    "Appealing to the symmetry of the dice and the impartiality of the laws of physics, we\n",
    "have that \n",
    "\n",
    "- $\\mathrm{Prob}(\\{6\\}) = 1/6$, because all six numbers are equally likely and exactly one must occur.\n",
    "\n",
    "- $\\mathrm{Prob}(\\{2,4,6\\}) = 3/6 = 1/2$ or \n",
    "\n",
    "  - $\\mathrm{Prob}(\\{2\\})+\\mathrm{Prob}(\\{4\\})+\\mathrm{Prob}(\\{6\\}) = 1/6 + 1/6 + 1/6 = 1/2$.\n",
    "\n",
    "- $\\mathrm{Prob}(\\{3,5\\}) = 2/6 = 1/3$.\n",
    "\n",
    "  - $\\mathrm{Prob}(\\{3,5\\}) = \\mathrm{Prob}(\\{1,3,5\\})\\times\\mathrm{Prob}(\\{3,4,5,6\\}) = 3/6 \\times 4/6 = 1/3$.\n",
    "\n",
    "\n",
    "\n",
    "The second illustrates that \n",
    "\n",
    "- $\\mathrm{P}(A\\mathrm{\\ and\\ } B) = \\mathrm{P}(A)+\\mathrm{P}(B)$ when $A$ and $B$ are *mutually exclusive*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 2\n",
    "\n",
    "The way to discredit the prosecution's probability is to \n",
    "focus on the DNA testing lab's **failure rate**. Let \n",
    "$M$ be the event of a reported match between two samples.\n",
    "Let $T$ be the event of a true match, and let $F$ be \n",
    "the event of a falsely reported match. Then, \n",
    "$P(T)=10^{-6}$, $P(M)=P(T\\cup F)=P(T)+P(F)=10^{-6}+10^{-5}$\n",
    "and so,\n",
    "\n",
    "$$\n",
    "\\mathrm{P}(T\\mid M)=\\frac{P(T\\cap M)}{P(M)}=\\frac{P(T)}{P(M)}\n",
    "=\\frac{10^{-6}}{10^{-6}+10^{-5}}=\\frac{1}{11}.\n",
    "$$\n",
    "\n",
    "Another way of saying this is that, if we test every one of\n",
    "the $2,000,000$ women who may be guilty, we can expect \n",
    "$2$ (one in a million) to show a true match and the lab \n",
    "to falsely report another $20$ (one in $100,000$) as also \n",
    "matching. Hence, of the $22$ who are reported to match, \n",
    "only $2$ actually match and \n",
    "$2/22=1/11 < 10\\%$ as above.\n",
    "\n",
    "**This means**, we can imagine telling the jury, that there\n",
    "is a less than 10% probability that the defendant's DNA matches\n",
    "the DNA found at the crime scene. Moreover, in the absence of \n",
    "other evidence, there are 22 other \n",
    "defendant candidates and, by choosing one at random, the \n",
    "probability that we have the guilty one is only \n",
    "$1/22$, or about 4.5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 3\n",
    "\n",
    "1. $\\boldsymbol{v}=(1,\\epsilon)^T$ and so \n",
    "$\\Vert\\boldsymbol{v}\\Vert_1 = \\sum_i\\vert v_i\\vert = 1+\\epsilon$ and\n",
    "$\\Vert\\boldsymbol{v}\\Vert_2^2 = \\sum_i\\vert v_i\\vert^2 = 1+\\epsilon^2$.\n",
    "\n",
    "2. $\\boldsymbol{v}=(1-\\delta,\\epsilon)^T$ and so \n",
    "$\\Vert\\boldsymbol{v}\\Vert_1 = \\sum_i\\vert v_i\\vert = 1-\\delta+\\epsilon$ and\n",
    "$\\Vert\\boldsymbol{v}\\Vert_2^2 = \\sum_i\\vert v_i\\vert^2 = (1-\\delta)^2+\\epsilon^2\n",
    "= 1-2\\delta+\\delta^2+\\epsilon^2$.\n",
    "\n",
    "3. $\\boldsymbol{v}=(1,\\epsilon-\\delta)^T$ and so \n",
    "$\\Vert\\boldsymbol{v}\\Vert_1 = \\sum_i\\vert v_i\\vert = 1+\\epsilon-\\delta$ and\n",
    "$\\Vert\\boldsymbol{v}\\Vert_2^2 = \\sum_i\\vert v_i\\vert^2 = 1+(\\epsilon-\\delta)^2\n",
    "= 1+\\epsilon^2-2\\epsilon\\delta+\\delta^2$.\n",
    "\n",
    "4. Yes, the norm is reduced by $\\delta$ in both cases.\n",
    "\n",
    "5. The $\\ell_2$ norm is reduced by $(2-\\delta)\\delta$ when the\n",
    "larger component is reduced, but only by $(2\\epsilon-\\delta)\\delta$ when\n",
    "the smaller component is reduced.\n",
    "\n",
    "6. Sparsity results from zeros being introduced into the coeffcient vector.\n",
    "A small value need only be reduced by a correspondingly small amount to\n",
    "become zero. The argument above suggests that small values only get a\n",
    "correspondingly small reduction in the $\\ell_2$ norm, but get equal \n",
    "reduction as larger values in the $\\ell_1$ norm. This leads us to believe that \n",
    "there is an increased possibility of zeroes being introduced in the LASSO case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 4\n",
    "\n",
    "The midpoint is $\\hat{\\boldsymbol{x}} = (\\hat{x}_1,\\hat{x}_2)\n",
    "=  \\frac{1}{2}\\Big(\\boldsymbol{q}+\\boldsymbol{r}\\Big)$\n",
    "and the straight line must go through that point.\n",
    "\n",
    "The straight line must be orthogonal to $\\boldsymbol{q}-\\boldsymbol{r}$ and so its\n",
    "gradient must be $m=(q_1-r_1)/(r_2-q_2)$.\n",
    "\n",
    "This line has the general form of equation,\n",
    "\n",
    "$$\n",
    "x_2 - \\hat{x}_2 = \\left(\\frac{q_1-r_1}{r_2-q_2}\\right)(x_1-\\hat{x}_1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the specific case given we have \n",
    "$\\hat{\\boldsymbol{x}} = (\\hat{x}_1,\\hat{x}_2)\n",
    "=  \\frac{1}{2}\\Big(5+2,1+3\\Big)= \\frac{1}{2}(7,4)$,\n",
    "and with $\\boldsymbol{q} = (5,1)$ and $\\boldsymbol{r} = (2,3)$\n",
    "we have,\n",
    "\n",
    "$$\n",
    "x_2 - \\frac{4}{2} = \\left(\\frac{5-2}{3-1}\\right)\\left(x_1-\\frac{7}{2}\\right).\n",
    "$$\n",
    "\n",
    "Or, simplified,\n",
    "\n",
    "$$\n",
    "x_2\n",
    "= \\frac{3}{2}x_1-\\frac{3}{2}\\frac{7}{2} + \\frac{4}{2}\n",
    "= \\frac{3}{2}x_1-\\frac{21}{4} + \\frac{8}{4}\n",
    "= \\frac{3}{2}x_1-\\frac{13}{4}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 5\n",
    "\n",
    "We have $(w_1,w_2)^T\\cdot(x_1,x_2)^T = \\phi$ with $(w_1,w_2)^T=(-1,1)^T$\n",
    "and $\\phi=1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 6\n",
    "\n",
    "We use the formula we derived. With $\\boldsymbol{q}=(2,1)^T$,\n",
    "\n",
    "$$\n",
    "d = \\frac{\\phi-\\boldsymbol{w}^T\\boldsymbol{q}}{\\Vert\\boldsymbol{w}\\Vert_2}\n",
    "= \\frac{1-(-1,1)(2,1)^T}{\\sqrt{2}}\n",
    "= \\frac{2}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "and so $d=\\surd 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Answer 6\n",
    "w = np.array([[-1],[1]])\n",
    "q = np.array([[2],[1]])\n",
    "phi = 1\n",
    "print(w)\n",
    "print(q)\n",
    "print(np.linalg.norm(w))\n",
    "d = (phi - np.ndarray.item(w.T.dot(q)))/np.linalg.norm(w)\n",
    "print(d)\n",
    "d = (phi - np.matmul(w.T,q))/np.linalg.norm(w)\n",
    "print(d)\n",
    "d = (phi - np.vdot(w.T,q))/np.linalg.norm(w)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 7\n",
    "\n",
    "Here is a fully worked example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x1 = np.arange(-2,3,1)\n",
    "x2 = np.arange(-2,3,1)\n",
    "print(x1, x2)\n",
    "import numpy.matlib\n",
    "N = x1.shape[0]\n",
    "X1grid = np.matlib.repmat(x1,N,1)\n",
    "X2grid = np.matlib.repmat(x2,N,1).T\n",
    "print('X1grid = \\n', X1grid, '\\n and X2grid = \\n', X2grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 8\n",
    "\n",
    "Here is a fully worked example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = X1grid + X2grid\n",
    "indx = y < 0\n",
    "plt.scatter(X1grid[indx],X2grid[indx], color='blue')\n",
    "plt.scatter(X1grid[~indx],X2grid[~indx], color='red')\n",
    "#print(y)\n",
    "#print(indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 9\n",
    "\n",
    "Here is a fully worked example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X1grid[indx],X2grid[indx], color='blue')\n",
    "plt.plot(X1grid[~indx],X2grid[~indx], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X1grid[indx],X2grid[indx], '.b')\n",
    "plt.plot(X1grid[~indx],X2grid[~indx], '.r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 10\n",
    "\n",
    "Here is a fully worked example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X1f = X1grid.flatten()\n",
    "X2f = X2grid.flatten()\n",
    "indxf = indx.flatten()\n",
    "print('X1f = \\n', X1f)\n",
    "print('X2f = \\n', X2f)\n",
    "print('indxf = \\n', indxf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X1f[indxf],X2f[indxf], color='blue')\n",
    "plt.scatter(X1f[~indxf],X2f[~indxf], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X1f[indxf],X2f[indxf], '.b')\n",
    "plt.plot(X1f[~indxf],X2f[~indxf], '.r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 11\n",
    "\n",
    "We have in general...\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x} = (x_0, x_1, \\ldots, x_N)^T,\n",
    "\\boldsymbol{y} = (y_0, y_1, \\ldots, y_M)^T,\n",
    "\\boldsymbol{y} =\n",
    "\\sigma(\\boldsymbol{W}^T\\boldsymbol{x}+\\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "Here for a decision boundary of $-7x_1 + 3x_2 + 4=0$ we choose\n",
    "$\\boldsymbol{W} = (-7, 3)^T$ and $b$ = 4. Then\n",
    "\n",
    "$$\n",
    "y = \\mathcal{H}(\\boldsymbol{W}^T\\boldsymbol{x}+b).\n",
    "$$\n",
    "\n",
    "Note that both $y$ and $b$ are scalars here. The equation of the\n",
    "decision in boundary can also be written as\n",
    "$x_2=(7x_1-4)/3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "W = np.array([[-7,3]]).T\n",
    "b = 4\n",
    "# find y for input x = (-4,3)\n",
    "X = np.array([[-4,3]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = (-4,3), y = ', y)\n",
    "# find y for input x = (6,2)\n",
    "X = np.array([[6,2]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = ( 6,2), y = ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s = 0.1\n",
    "x1 = np.arange(0,2+s,s)\n",
    "x2 = np.arange(0,2+s,s)\n",
    "X = np.zeros([2,1])\n",
    "N = x1.shape[0]\n",
    "y = np.zeros([N,N])\n",
    "import numpy.matlib\n",
    "X1grid = np.matlib.repmat(x1,N,1)\n",
    "X2grid = np.matlib.repmat(x2,N,1).T\n",
    "\n",
    "for i in range(N):\n",
    "  for j in range(N):\n",
    "    X[0] = X1grid[i,j]\n",
    "    X[1] = X2grid[i,j]\n",
    "    y[i,j] = np.heaviside(W.T @ X + b, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "indx = (y < 0.5)\n",
    "plt.scatter(X1grid[ indx],X2grid[ indx], color='blue')\n",
    "plt.scatter(X1grid[~indx],X2grid[~indx], color='red')\n",
    "P1x=0.5\n",
    "P2x=1.5\n",
    "plt.plot([P1x, P2x], [(7*P1x-4)/3, (7*P2x-4)/3], color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 12\n",
    "\n",
    "We have in general...\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x} = (x_0, x_1, \\ldots, x_N)^T,\n",
    "\\boldsymbol{y} = (y_0, y_1, \\ldots, y_M)^T,\n",
    "\\boldsymbol{y} =\n",
    "\\sigma(\\boldsymbol{W}^T\\boldsymbol{x}+\\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "Here for decision boundaries of\n",
    "$5x_1 + 3x_2 + 6=0$ and $4x_1 + 7x_2 + 3=0$\n",
    "we choose\n",
    "$\\boldsymbol{W} = {5\\ \\ 4\\choose 3\\ \\ 7}$ and\n",
    "$\\boldsymbol{b}= {6 \\choose 3}$. Then\n",
    "\n",
    "$$\n",
    "\\boldsymbol{y} = \\mathcal{H}(\\boldsymbol{W}^T\\boldsymbol{x}+\\boldsymbol{b}).\n",
    "$$\n",
    "\n",
    "The equations of the decision in boundaries can also be written as\n",
    "$x_2=-(5x_1 + 6)/3$ and $x_2=-(4x_1 + 3)/7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# here is the neural network definition\n",
    "W = np.array([[5,4],[3,7]])\n",
    "b = np.array([[6,3]]).T\n",
    "# find y for input x = (-4,3)\n",
    "X = np.array([[-4,3]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = (-4,3), y = \\n', y)\n",
    "# find y for input x = (6,2)\n",
    "X = np.array([[6,2]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = ( 6,2), y = \\n', y)\n",
    "# find y for input x = (-6,2)\n",
    "X = np.array([[-6,2]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = (-6,2), y = \\n', y)\n",
    "# find y for input x = (6,-6)\n",
    "X = np.array([[6,-6]]).T\n",
    "y = np.heaviside(W.T@X+b,0)\n",
    "print('For input x = ( 6,-6), y = \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# two variable, output and input\n",
    "s = 1\n",
    "x1 = np.arange(-10,10+s,s)\n",
    "x2 = np.arange(-10,10+s,s)\n",
    "X = np.zeros([2,1])\n",
    "N = x1.shape[0]\n",
    "y = np.zeros([2,N,N])\n",
    "import numpy.matlib\n",
    "X1grid = np.matlib.repmat(x1,N,1)\n",
    "X2grid = np.matlib.repmat(x2,N,1).T\n",
    "\n",
    "for i in range(N):\n",
    "  for j in range(N):\n",
    "    X[0] = X1grid[i,j]\n",
    "    X[1] = X2grid[i,j]\n",
    "    y[:,[i],[j]] = np.heaviside(W.T @ X + b, 0)\n",
    "\n",
    "indx0 = (y[0,:] < 0.5)\n",
    "indx1 = (y[1,:] < 0.5)\n",
    "indx00 = np.logical_and( indx0, indx1)\n",
    "indx11 = np.logical_and(~indx0,~indx1)\n",
    "indx01 = np.logical_and( indx0,~indx1)\n",
    "indx10 = np.logical_and(~indx0, indx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X1grid[indx00], X2grid[indx00],15, color='brown')\n",
    "plt.scatter(X1grid[indx11], X2grid[indx11],15, color='red')\n",
    "plt.scatter(X1grid[indx01], X2grid[indx01],15, color='green')\n",
    "plt.scatter(X1grid[indx10], X2grid[indx10],15 , color='blue')\n",
    "P1x=-7\n",
    "P2x=4\n",
    "plt.plot([P1x, P2x], [-(5*P1x + 6)/3, -(5*P2x + 6)/3], ':k')\n",
    "plt.plot([P1x, P2x], [-(4*P1x + 3)/7, -(4*P2x + 3)/7], '--k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 13\n",
    "\n",
    "First we just count them up...\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>test pass</th>\n",
    "    <td>4</td>\n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>test fail</th>\n",
    "    <td>6</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <th>pred pass</th>\n",
    "    <th>pred fail</th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "In code we can just write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_test = np.array([1,1,0,1,0,1,0,1,0,1,1,0,1,0,1,0,0,1,0])\n",
    "y_pred = np.array([1,0,1,0,1,0,1,0,1,0,1,0,0,1,1,0,1,1,0])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "accsc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does this surprise you? Why is it not the same?\n",
    "\n",
    "It's because the values are used to index the matrix. We can alter them like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_test = ~y_test\n",
    "y_pred = ~y_pred\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cmplot = ConfusionMatrixDisplay(cm, display_labels=range(2))\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "cmplot.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is also possible to use `True` and `False`, or multi=classes, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_test = np.array([True, True, False, True, False, False, True])\n",
    "y_pred = np.array([True, False, True, False, True, False, True])\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "y_test = np.array([1,2,0,1,0,1,0,2,0,1,2,0,1,0,1,2,2,1,0])\n",
    "y_pred = np.array([1,0,1,0,1,2,1,0,2,0,2,0,2,1,1,0,1,1,0])\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer 14\n",
    "\n",
    "We need the covariance matrix and its eigen-system in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Case 1 - data is already centred - check\n",
    "X = np.array([[3, 3], [-3, -3]])\n",
    "print('X = \\n',X)\n",
    "print(f'Column means: col 1, {X[:,0].mean()} and col 2, {X[:,0].mean()}')\n",
    "# and the empirical covariance matrix\n",
    "N = 2\n",
    "S = 1/N*X.T @ X\n",
    "print('S = \\n',S)\n",
    "# solve the eigenvalue problem||\n",
    "lmda, V = np.linalg.eig(S)\n",
    "print('evals = ', lmda)\n",
    "print('evecs = \\n', V)\n",
    "print('( 3, 3) distance along PC1 = ', X[0,:].T @ V[:,0])\n",
    "print('(-3,-3) distance along PC1 = ', X[1,:].T @ V[:,0])\n",
    "print('( 3, 3) distance along PC2 = ', X[0,:].T @ V[:,1])\n",
    "print('(-3,-3) distance along PC2 = ', X[1,:].T @ V[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Case 2 - data is already centred - check\n",
    "X = np.array([[-3, -3], [1,2], [2,1]])\n",
    "print('X = \\n',X)\n",
    "print(f'Column means: col 1, {X[:,0].mean()} and col 2, {X[:,1].mean()}')\n",
    "# and the empirical covariance matrix\n",
    "N = 3\n",
    "S = 1/N*X.T @ X\n",
    "print('S = \\n',S)\n",
    "# solve the eigenvalue problem\n",
    "lmda, V = np.linalg.eig(S)\n",
    "print('evals = ', lmda)\n",
    "print('evecs = \\n', V)\n",
    "print('(-3,-3) distance along PC1 = ', X[0,:].T @ V[:,0])\n",
    "print('(-3,-3) distance along PC2 = ', X[0,:].T @ V[:,1])\n",
    "print('( 1, 2) distance along PC1 = ', X[1,:].T @ V[:,0])\n",
    "print('( 1, 2) distance along PC2 = ', X[1,:].T @ V[:,1])\n",
    "print('( 2, 1) distance along PC1 = ', X[2,:].T @ V[:,0])\n",
    "print('( 2, 1) distance along PC2 = ', X[2,:].T @ V[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the first case there is just one principal component. \n",
    "The data are one-dimensional. The empirical variance is \n",
    "$2\\times\\frac{1}{2}(3^2 + (-3)^2) = 18$ and is all\n",
    "captured by the only non-zero eigenvalue.\n",
    "\n",
    "In the second case the variance is\n",
    "$2\\times\\frac{1}{3}(3^2+1^2+2^2)=28/3\\approx 9.333...$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Technical Notes, Production and Archiving\n",
    "\n",
    "Ignore the material below. What follows is not relevant to the material being taught."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Production Workflow\n",
    "\n",
    "- Finalise the notebook material above\n",
    "- Clear and fresh run of entire notebook\n",
    "- Create html slide show:\n",
    "  - `jupyter nbconvert --to slides E_worksheet.ipynb `\n",
    "- Set `OUTPUTTING=1` below\n",
    "- Comment out the display of web-sourced diagrams\n",
    "- Clear and fresh run of entire notebook\n",
    "- Comment back in the display of web-sourced diagrams\n",
    "- Clear all cell output\n",
    "- Set `OUTPUTTING=0` below\n",
    "- Save\n",
    "- git add, commit and push to FML\n",
    "- copy PDF, HTML etc to web site\n",
    "  - git add, commit and push\n",
    "- rebuild binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some of this originated from\n",
    "\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n",
    "\n",
    "These lines create a back up of the notebook. They can be ignored.\n",
    "\n",
    "At some point this is better as a bash script outside of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "NBROOTNAME='E_worksheet'\n",
    "OUTPUTTING=0\n",
    "\n",
    "if [ $OUTPUTTING -eq 1 ]; then\n",
    "  jupyter nbconvert --to html $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.html ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.html\n",
    "  mv -f $NBROOTNAME.html ./formats/html/\n",
    "\n",
    "  jupyter nbconvert --to pdf $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.pdf ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pdf\n",
    "  mv -f $NBROOTNAME.pdf ./formats/pdf/\n",
    "\n",
    "  jupyter nbconvert --to script $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.py ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.py\n",
    "  mv -f $NBROOTNAME.py ./formats/py/\n",
    "else\n",
    "  echo 'Not Generating html, pdf and py output versions'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
