{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concepts\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "<https://www.brunel.ac.uk/people/simon-shaw>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses python</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td> \n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Penguins: Exploring Some Key Concepts\n",
    "\n",
    "We'll be using the *penguins* data that we have seen before in order\n",
    "to introduce, understand and work with these concepts:\n",
    "\n",
    "- Binary Classifiers, Confusion Matrices, Decision Boundaries\n",
    "- True and False Postives and Negatives\n",
    "- sensitivity, specificity, precision, recall, F1 score, prevalence,\n",
    "\n",
    "These terms and their usage will be coming back again and again.\n",
    "\n",
    "We will also discuss the fairness dilemma, using Sumpter (2021) as a source:\n",
    "\n",
    "- Sumpter (2021) Ethics in Machine Learning, In: Machine Learning: A First Course for Engineers and Scientists, Cambridge University Press\n",
    "\n",
    "This is no more than Chapter 12 of our reference book [MLFCES] as introduced in an earlier session:\n",
    "\n",
    "- MLFCES: Machine Learning: A First Course for Engineers and Scientists, by Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön. Cambridge University Press. <http://smlbook.org>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First we bring in our standard imports...\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... plus the newer ones we learned about last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to where we were\n",
    "\n",
    "We'll bring in the penguins data set and clean it up just as in the previous session. \n",
    "We do this bit quickly because there is nothing new here.\n",
    "\n",
    "> **NOTE:** *we wont always be going through such detailed coding. The purpose of these\n",
    "introductory sessions is to set you up with __code templates__ that you can take and\n",
    "adjust to suit your needs.* Once you have those we will be able to spend more time \n",
    "looking at the machine learning models themselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp = sns.load_dataset('penguins')\n",
    "dfp2 = dfp.dropna()\n",
    "dfp2.isna().sum()\n",
    "dfp2 = dfp2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have already seen how we can use $k$-NN to predict the species in\n",
    "column zero, from the numerical data in columns 3 - 6 (indexed as 2 - 5).\n",
    "\n",
    "Here is that code again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We fitted the model using the Manhattan metric:\n",
    "$\\Vert\\boldsymbol{x}^* - \\boldsymbol{x}_i\\Vert_1$, \n",
    "and then plotted the confusion matrix and performance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create our labelled training and test data sets with 60/40 train/test split\n",
    "X = dfp2.iloc[:, 2:6].values\n",
    "y = dfp2.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# obtain the classifier and fit it using 2 nearest neighbours\n",
    "# and the Manhattan norm\n",
    "classifier = KNeighborsClassifier(n_neighbors=2, p=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Now use the fitted model from the training data to predict\n",
    "# from the test data.\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a confusion matrix to assess the performance\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "clsrep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print(clsrep)\n",
    "\n",
    "accsc = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\", accsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Confusion Matrix\n",
    "\n",
    "The confusion matrix is square with the same number of rows/columns\n",
    "as there are values for the label. In our case there are three \n",
    "possible label values: *Adelie*, *Chinstrap*, and *Gentoo*. We can refer\n",
    "to these as group 1, 2 and 3.\n",
    "\n",
    "The entry in row $i$ and column $j$ of the confusion matrix tells\n",
    "us how many data points in `X_test` that were in group $i$ were\n",
    "predicted by the model to be in group $j$. For details see\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html>\n",
    "\n",
    "Now, the representation of the confusion matrix above is a numpy\n",
    "array and although it is useful for coding, it isn't very \n",
    "user friendly. The following code gives us something much nicer,\n",
    "and it is much easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cmplot = ConfusionMatrixDisplay(cm, display_labels=classifier.classes_)\n",
    "cmplot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now immediately get a feeling for *how good* the model is. The diagonal\n",
    "elements tell us how many species predictions match the true value. The\n",
    "off-diagonals tell us how many misses there are, and how they missed.\n",
    "\n",
    "For example, the number in the middle of the top row tells us how many Adelie\n",
    "penguins were mistakenly predicted to be Chinstraps.\n",
    "\n",
    "Also, the overall accuracy percentage can be determined by adding all the\n",
    "numbers in the matrix, calling the total $B$, and adding all the diagonal elements\n",
    "together, as $A$. The value of $A/B$ then tells us the proportion of correct \n",
    "predictions - and that is the *Accuracy* score above.\n",
    "\n",
    "We haven't yet properly reviewed the mathematical concept and notion of\n",
    "a matrix yet, although we will do soon. We will be coming back to \n",
    "confusion matrices over and over again though. \n",
    "\n",
    "The confusion matrix can be large or small. A particularly important case\n",
    "is the $2\\times 2$ case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Classifier\n",
    "\n",
    "What we are doing above is _**classifying**_: given data from a specific observation\n",
    "we are deciding what class that observation belongs to.\n",
    "\n",
    "In the case above we are attempting to use physiological data to classify the \n",
    "species of penguin.\n",
    "\n",
    "A particularly important type of classifier arises when we are simply trying to\n",
    "decide 'Yes' or 'No', or 'True' or 'False', 'Guilty' or 'Innocent', \n",
    "'Diseased' or 'Healthy' and so on.\n",
    "\n",
    "There are only two classes: generically termed **positive** and **negative**.\n",
    "\n",
    "Such a classifier is called a **Binary Classifier**, and the confusion matrix bears\n",
    "further discussion in this case.\n",
    "\n",
    "Let's return to the penguin data and try to predict gender from the other\n",
    "physiological characteristics. This will be a binary classifier, because \n",
    "it will either predict 'Female' (**positive**) or 'Not-Female' (**negative**).\n",
    "\n",
    "Let's start by recalling the structure of the data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dfp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can double check that 'Female' and 'Male' are the only entries in the\n",
    "gender column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp2['sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting gender from just two data items\n",
    "\n",
    "Below we want to introduce the notion of a **decision boundary**. This is \n",
    "best done graphically and for that we want to work with 2D plots. \n",
    "\n",
    "This means that we want our $k$-NN classifier to be able to predict gender from\n",
    "just two columns of data.\n",
    "\n",
    "The question then, is which two columns to choose?\n",
    "\n",
    "Let's have a look at the choices available to us. We could try looking at the table...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfp2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... but how are we ever going to be able to make a good decision as to which\n",
    "pair of columns like that?\n",
    "\n",
    "Here is a better way (at least if you don't have too many columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dfp2, corner=True, hue='sex', height=1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It looks from this that *bill depth* and *body mass* should work well\n",
    "to separate out genders.\n",
    "\n",
    "\n",
    "Even here, the term **Decision Boundary** might make some intuitive sense\n",
    "to you. What do you think it might mean?\n",
    "\n",
    "Let's build the binary classifier using just these two columns, and \n",
    "get the confusion matrix just as before.\n",
    "\n",
    "We'll do it all in one go, because we've seen all the steps before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# extract the input/features X, and the output/labels y\n",
    "X = dfp2.iloc[:, [3,5]].values\n",
    "y = dfp2.iloc[:, 6].values\n",
    "# optionally, print the first few just to check\n",
    "print(X[0:4,:])\n",
    "print(y[0:4])\n",
    "# bifurcate the data to get a 40% test set, and 60% training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)\n",
    "\n",
    "# print out the sizes of the train and test sets\n",
    "print('\\n')\n",
    "print('X_train has ', X_train.shape[0], ' rows and ', X_train.shape[1], ' columns')\n",
    "print('y_train has ', y_train.shape[0], ' rows')\n",
    "print('\\n')\n",
    "print('X_test has ', X_test.shape[0], ' rows and ', X_test.shape[1], ' columns')\n",
    "print('y_test has ', y_test.shape[0], ' rows')\n",
    "print('\\n')\n",
    "\n",
    "# get scaling parameters from the training data, \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scale the training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# now classify using k=2, p=1 - as before\n",
    "classifier = KNeighborsClassifier(n_neighbors=2, p=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "# and then make predictions from the test data \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# compare the predictions with the ground truth, or hold-out set, y_test\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# and print the results out\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "clsrep = classification_report(y_test, y_pred)\n",
    "print('\\n')\n",
    "print(\"Classification Report:\",)\n",
    "print(clsrep)\n",
    "accsc = accuracy_score(y_test,y_pred)\n",
    "print('\\n')\n",
    "print(\"Accuracy:\", accsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have seen before that there is another way to display the \n",
    "confusion matrix that is friendlier on the eye. We'll do this\n",
    "below.\n",
    "\n",
    "Alos, we note from above that there are `134` data points in\n",
    "the test set and so we should expect the numbers in the confusion matrix\n",
    "to sum to that number. It's a useful check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(cm.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cmplot = ConfusionMatrixDisplay(cm, display_labels=classifier.classes_)\n",
    "cmplot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True and False Positives and Negatives\n",
    "\n",
    "There are a few particularly important pieces of terminology that \n",
    "are associated with binary classifiers. \n",
    "\n",
    "- **TP**, *True Positives*: This is the number of test data points\n",
    "that are labelled **POSITIVE** for which the classifier correctly\n",
    "(**truly**) predicted them as **POSITIVE**.\n",
    "\n",
    "- **FP**, *False Positives*: This is the number of test data points\n",
    "that are labelled **NEGATIVE** for which the classifier incorrectly\n",
    "(**falsely**) predicted them as **POSITIVE**.\n",
    "\n",
    "Since we are regarding **Female** as **POSITIVE**, we can see these \n",
    "numbers in the first column above.\n",
    "\n",
    "Furthermore,\n",
    "\n",
    "- **FN**, *False Negatives*. This is the number of test data points\n",
    "that are labelled **POSITIVE** for which the classifier incorrectly\n",
    "(**falsely**) predicted them as **NEGATIVE**.\n",
    "\n",
    "- **TN**, *True Negatives*. This is the number of test data points\n",
    "that are labelled **NEGATIVE** for which the classifier incorrectly\n",
    "(**truly**) predicted them as **NEGATIVE**.\n",
    "\n",
    "These last two are in the second column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Diagrammatically we have\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcc}\n",
    "  \\begin{array}{r}  \\text{target, or true} \\\\ \\text{label/class}  \\end{array}\\quad\n",
    "  &\n",
    "  \\begin{array}{c}  + \\\\ -  \\end{array}\\!\\!\n",
    "  &\n",
    "  \\left(\n",
    "  \\begin{array}{cc}\n",
    "  \\mathrm{TP} & \\mathrm{FN} \\\\\n",
    "  \\mathrm{FP} & \\mathrm{TN} \\\\\n",
    "  \\end{array}\n",
    "  \\right)\n",
    "\\\\\n",
    "& & \\begin{array}{cc} + & - \\end{array}\n",
    "\\\\\n",
    "& & \\text{output, or predicted}\n",
    "\\\\\n",
    "& & \\text{label/class}\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "We can access these numbers in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "TP = cm[0,0]; FP = cm[1,0]; FN = cm[0,1]; TN = cm[1,1]\n",
    "print(TP, FN)\n",
    "print(FP, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Related Formulae and Measures\n",
    "\n",
    "Once we have these data we can compute a wide variety of different performance\n",
    "indicators. Here are the most commonly used, where we use $\\mathrm{P}$ and\n",
    "$\\mathrm{N}$ for the number of positives and negatives overall in the test set.\n",
    "\n",
    "- **Prevalence**:\n",
    "\n",
    "$$\n",
    "\\mathrm{Prevalence} = \\frac{\\mathrm{P}}{\\mathrm{P}+\\mathrm{N}}\n",
    "$$\n",
    "\n",
    "- TPR: **True Positive Rate**, *sensitivity*, *recall*:\n",
    "\n",
    "$$\n",
    "\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{P}} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\n",
    "$$\n",
    "\n",
    "\n",
    "- TNR: **True Negative Rate**, *specificity*, *selectivity*:\n",
    "\n",
    "$$\n",
    "\\mathrm{TNR} = \\frac{\\mathrm{TN}}{\\mathrm{N}} = \\frac{\\mathrm{TN}}{\\mathrm{TN}+\\mathrm{FP}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- FPR: **False Positive Rate**:\n",
    "\n",
    "$$\n",
    "\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{N}} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}\n",
    "$$\n",
    "\n",
    "- FNR: **False Negative Rate**:\n",
    "\n",
    "$$\n",
    "\\mathrm{FNR} = \\frac{\\mathrm{FN}}{\\mathrm{P}} = \\frac{\\mathrm{FN}}{\\mathrm{FN}+\\mathrm{TP}}\n",
    "$$\n",
    "\n",
    "- **Accuracy**:\n",
    "\n",
    "$$\n",
    "\\mathrm{Accuracy} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{P}+\\mathrm{N}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Balanced Accuracy**:\n",
    "\n",
    "$$\n",
    "\\mathrm{Balanced\\ Accuracy} = \\frac{1}{2}\\left(\\mathrm{TPR}+\\mathrm{TNR}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- PPV: **Positive Predictive Value**, *precision*:\n",
    "\n",
    "$$\n",
    "\\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- NPV: **Negative Predictive Value**:\n",
    "\n",
    "$$\n",
    "\\mathrm{NPV} = \\frac{\\mathrm{TN}}{\\mathrm{TN}+\\mathrm{FN}}\n",
    "$$\n",
    "\n",
    "- F1 score: this is the *harmonic mean* of precision and sensitivity:\n",
    "\n",
    "$$\n",
    "\\mathrm{F1} = \\left(\n",
    "\\frac{\\displaystyle\\left(\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}\\right)^{-1}\n",
    "      +\n",
    "      \\left(\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\\right)^{-1}}{2}\n",
    "\\right)^{-1}\n",
    "= \\frac{2\\,\\mathrm{TP}}{2\\,\\mathrm{TP}+\\mathrm{FP}+\\mathrm{FN}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's calculate some of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P=TP+FN\n",
    "N=FP+TN\n",
    "print('P (# positives) = ', P)\n",
    "print('N (# negatives) = ', N)\n",
    "print('TPR (recall)    = ', TP/(TP+FN))\n",
    "print('PPV (precision) = ', TP/(TP+FP))\n",
    "print('F1              = ', 2*TP/(2*TP+FP+FN))\n",
    "print('Accuracy        = ', (TP+TN)/(P+N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But - remember this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report:\",)\n",
    "print(clsrep)\n",
    "accsc = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\", accsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With *Females* as *Positive* we can read off the **precision**,\n",
    "**recall** and **F1 score** from the table, and obtain the\n",
    "**accuracy** as a by-product of the classification as well.\n",
    "\n",
    "Also, **support** tells us what $\\mathrm{P}$ is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision Boundaries\n",
    "\n",
    "Let's now try and develop a bit more intuition as to how this classifier\n",
    "works, and what we can expect from it.\n",
    "\n",
    "The following observation will be relevant to other classification\n",
    "techniques as well.\n",
    "\n",
    "Let's recap:\n",
    "\n",
    "- we have a training data set of features.\n",
    "- these features are points in space.\n",
    "- each training point has a label - its *class*\n",
    "- we introduce a new point: it will have some 'nearest neighbours'\n",
    "- we use the nearest neighbours' classes to classify the new point\n",
    "\n",
    "Imagine this for a binary classifier where the the data points,\n",
    "the features, are points in 2D.\n",
    "\n",
    "We can imagine that the binary output can be coloured. For example:\n",
    "\n",
    "> **RED** for **POSITIVE** (i.e. *female*)\n",
    "\n",
    "> **BLUE** for **NEGATIVE** (i.e. *male*)\n",
    "\n",
    "We can already see something like this from the scatter plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfp2, x=\"bill_depth_mm\", y=\"body_mass_g\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From this diagram we can imagine drawing a line that attempts to separate the\n",
    "RED and BLUE regions. Such a line is called a **Decision Boundary**.\n",
    "\n",
    "On one side of the boundary we decide **POSITIVE**, and on the other we\n",
    "decide **NEGATIVE**.\n",
    "\n",
    "We're not going to actually get a pen and draw this line though.\n",
    "\n",
    "We're going to illustrate the decision boundary with code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting the decision boundary\n",
    "\n",
    "We are going to do this at a low level using `matplotlib`. First let's look\n",
    "closely at our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We're going to find all the array indices for **POSITIVE** (*Female*)\n",
    "predictions and all the indices for **NEGATIVE** (*Male*) predictions.\n",
    "\n",
    "We can print them out to see what is going on, but we don't have to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "indxM = np.where(y_pred == 'Male')[0]\n",
    "indxF = np.where(y_pred != 'Male')[0]\n",
    "print(indxM, len(indxM))\n",
    "print(indxF, len(indxF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can visualize these predictions with a scatter plot like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test[indxM,0], X_test[indxM,1], color='blue')\n",
    "plt.scatter(X_test[indxF,0], X_test[indxF,1], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And we can recall the ground truth in the whole data set like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfp2, x=\"bill_depth_mm\", y=\"body_mass_g\", hue=\"sex\")\n",
    "print(dfp2.shape, 0.4*dfp2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "They aren't the same. They shouldn't be. This is because:\n",
    "\n",
    "- The number of predictions is less than the number of data points\n",
    "because of the train-test split.\n",
    "\n",
    "- Also, the predictions may not be correct, so points at the same\n",
    "location in 2D may have different colours.\n",
    "\n",
    "We can easily check the first of these above by looking at the\n",
    "shape of the arrays like this... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test[indxM,:].shape)\n",
    "print(X_test[indxF,:].shape)\n",
    "print(X_test[indxM,:].shape[0] + X_test[indxF,:].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, these scatter plots don't really give us the separating line\n",
    "that we have been discussing - the **Decision Boundary**.\n",
    "\n",
    "That is going to take a bit more work.\n",
    "\n",
    "The idea is to decide on a range of values for the features in\n",
    "`X_test` and then to create a regular grid.\n",
    "\n",
    "We then predict the label on that regular grid and color the \n",
    "point accordingly. \n",
    "\n",
    "It is a bit involved, but here we go... The code was adapted from\n",
    "that found here:\n",
    "\n",
    "<https://hackernoon.com/how-to-plot-a-decision-boundary-for-machine-learning-algorithms-in-python-3o1n3w07>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# define bounds of the domain using max and min of our features\n",
    "x1min, x1max = X_test[:, 0].min()-1, X_test[:, 0].max()+1\n",
    "x2min, x2max = X_test[:, 1].min()-1, X_test[:, 1].max()+1\n",
    "\n",
    "# define the x and y scale - this sets up a point spacing of 0.1\n",
    "x1grid = np.arange(x1min, x1max, 0.1)\n",
    "x2grid = np.arange(x2min, x2max, 0.1)\n",
    "\n",
    "# create arrays for the grid coordinates\n",
    "xx1, xx2 = np.meshgrid(x1grid, x2grid)\n",
    "print('xx1.shape = ', xx1.shape)\n",
    "print('xx2.shape = ', xx2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is fine for plotting, but the prediction model needs just a\n",
    "list of pairs of features. So we have to flatten these grids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xx1xx2 = np.stack((xx1.flatten(), xx2.flatten()), axis=-1)\n",
    "print(xx1xx2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can predict the label at each of the grid points.\n",
    "\n",
    "> **NOTE:** `X_test` has already been normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(xx1xx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And then scatter plot these in different colours according to prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "indxF = np.where(y_pred == 'Female')[0]\n",
    "indxM = np.where(y_pred != 'Female')[0]\n",
    "plt.scatter(xx1xx2[indxM,0], xx1xx2[indxM,1], color='blue' , s=2)\n",
    "plt.scatter(xx1xx2[indxF,0], xx1xx2[indxF,1], color='red', s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# the ground truth of the entire data set we have seen earlier, it's this:\n",
    "sns.scatterplot(data=dfp2, x=\"bill_depth_mm\", y=\"body_mass_g\", hue=\"sex\")\n",
    "print(dfp2.shape, 0.4*dfp2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It would be nice to overlay these onto the decision boundary diagram.\n",
    "\n",
    "Well, first we plot these in matplotlib like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "indxM = np.where(y == 'Male')[0]\n",
    "indxF = np.where(y != 'Male')[0]\n",
    "plt.scatter(X[indxM,0], X[indxM,1], color='blue')\n",
    "plt.scatter(X[indxF,0], X[indxF,1], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is now just a case of repeating the decision boundary plot from\n",
    "earlier, and then following up with the one above. \n",
    "\n",
    "We have to do this in the **same cell** in order that they appear\n",
    "on the same set of axes.\n",
    "\n",
    "Remember also that the ground truth in `X` and `y` needs to be\n",
    "scaled. We do this by creating `X_trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# repeat the plot from above\n",
    "indxF = np.where(y_pred == 'Female')[0]\n",
    "indxM = np.where(y_pred != 'Female')[0]\n",
    "plt.scatter(xx1xx2[indxM,0], xx1xx2[indxM,1], color='blue' , s=2)\n",
    "plt.scatter(xx1xx2[indxF,0], xx1xx2[indxF,1], color='red', s=2)\n",
    "\n",
    "# scale the ground truth\n",
    "X_trans = scaler.transform(X)\n",
    "\n",
    "# now plot the ground truth using 'empty' circles\n",
    "indxM = np.where(y == 'Male')[0]\n",
    "indxF = np.where(y != 'Male')[0]\n",
    "plt.scatter(X_trans[indxM,0], X_trans[indxM,1], facecolors='w', edgecolors='b')\n",
    "plt.scatter(X_trans[indxF,0], X_trans[indxF,1], facecolors='w', edgecolors='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll come back to decision boundaries several times later on. It is worth\n",
    "noting that we did everything here in 2D because these cases are easy to plot\n",
    "and illustrate.\n",
    "\n",
    "If we had more than two features then we would need to plot the features in\n",
    "higher dimensional space - which is quite a challenge.\n",
    "\n",
    "Nonetheless, a decision boundary can still be imagined that, for a binary\n",
    "classifier, will separate these points into two disjoint regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fairness - setting up the discussion\n",
    "\n",
    "The last thing we are going to touch on here is the notion of \n",
    "**_fairness of a binary classifier_**.\n",
    "\n",
    "- what do we mean by this?\n",
    "- can a binary classifier ever be fair?\n",
    "\n",
    "As mentioned above, we'll be using Sumpter (2021) as a source:\n",
    "\n",
    "- Sumpter (2021) Ethics in Machine Learning, In: Machine Learning: A First Course for Engineers and Scientists, Cambridge University Press\n",
    "\n",
    "This is in Chapter 12 of our reference book [MLFCES]:\n",
    "\n",
    "- MLFCES: Machine Learning: A First Course for Engineers and Scientists, by Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön. Cambridge University Press. <http://smlbook.org>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider a binary classifier applied to a population containing $p>0$\n",
    "**POSITIVE** (or *true*) outcomes and $n>0$ **NEGATIVE** (or *false*) \n",
    "outcomes. We have seen that the confusion matrix takes this form:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcc}\n",
    "  \\begin{array}{r}  \\text{target} \\\\ \\text{or true}  \\end{array}\\quad\n",
    "  &\n",
    "  \\begin{array}{c}  + \\\\ -  \\end{array}\\!\\!\n",
    "  &\n",
    "  \\left(\n",
    "  \\begin{array}{cc}\n",
    "  \\mathrm{TP} & \\mathrm{FN} \\\\\n",
    "  \\mathrm{FP} & \\mathrm{TN} \\\\\n",
    "  \\end{array}\n",
    "  \\right)\n",
    "\\\\\n",
    "& & \\begin{array}{cc} + & - \\end{array}\n",
    "\\\\\n",
    "& & \\text{predicted}\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If there are $t$ TP's and $f$ FP's then:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "  \\begin{array}{c}  + \\\\ -  \\end{array}\\!\\!\n",
    "  &\n",
    "  \\left(\n",
    "  \\begin{array}{cc}\n",
    "  \\mathrm{TP} & \\mathrm{FN} \\\\\n",
    "  \\mathrm{FP} & \\mathrm{TN} \\\\\n",
    "  \\end{array}\n",
    "  \\right)\n",
    "\\\\\n",
    " & \\begin{array}{cc} + & - \\end{array}\n",
    "\\end{array}\n",
    "\\qquad\\qquad\\text{ becomes }\\qquad\\qquad\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "t & p-t \\\\\n",
    "f & n-f \\\\\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose now that this classifier is applied to data harvested from two\n",
    "distinct populations. It could be that the classifier is making a\n",
    "decision as to whether ...\n",
    "\n",
    "- a certain age range of people in various demographic groups are inclined to crime\n",
    "- individuals in various ethnic groups are entitled to healthcare\n",
    "- children in different regions should get extra academic help\n",
    "- how males and female respond to a certain treatment \n",
    "\n",
    "The question we want to consider is whether or not this classifier\n",
    "can **treat each group fairly**.\n",
    "\n",
    "Sumpter in [MLFCES] discusses it this way. We suppose that the classifier\n",
    "is applied to two separate groups, giving these two confusion matrices:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "t_1 & p_1-t_1 \\\\\n",
    "f_1 & n_1-f_1 \\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\qquad\\text{ and }\\qquad\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "t_2 & p_2-t_2 \\\\\n",
    "f_2 & n_2-f_2 \\\\\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "We note that\n",
    "\n",
    "- $n_1$, $p_1$, $n_2$, $p_2$ are beyond our control - they are simply 'facts'.\n",
    "- We do though assume that $n_1,\\, p_1,\\, n_2,\\, p_2 > 0$ (otherwise this is pointless).\n",
    "- $f_1$, $t_1$ and $f_2$, $t_2$ are a property of the model and how well it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remarks\n",
    "\n",
    "Following Sumpter's ideas we now ask if this classifier can be **_fair_**.\n",
    "Can we be sure that it performs the same on two different groups?\n",
    "\n",
    "To make progress on this question note again that in this scenario $p_i$ and $n_i$ are\n",
    "beyond our control for each group ($i=1$ and $i=2$) - they are just facts.\n",
    "\n",
    "Moreover, the $f_i$ and $t_i$ in each case are determined by the classification\n",
    "method chosen, and the configuration of the algorithm (the selection of\n",
    "**hyperparameters** for example). We have some control over these by \n",
    "our training procedure, but we cannot guarantee perfection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fairness\n",
    "\n",
    "We can attempt to tune the classifier by insisting that it performs *equally*\n",
    "on both groups. Sumpter does this by...\n",
    "\n",
    "- Asking that the FPR's are equal:\n",
    "\n",
    "$$\n",
    "\\frac{f_1}{n_1} = \\frac{f_2}{n_2}\n",
    "\\qquad\\Longrightarrow\\qquad\n",
    "f_1 = \\frac{f_2 n_1}{n_2}.\n",
    "$$\n",
    "\n",
    "- Asking that the TPR's are equal:\n",
    "\n",
    "$$\n",
    "\\frac{t_1}{p_1} = \\frac{t_2}{p_2}\n",
    "\\qquad\\Longrightarrow\\qquad\n",
    "t_1 = \\frac{t_2 p_1}{p_2}.\n",
    "$$\n",
    "\n",
    "- Asking for equal precision:\n",
    "\n",
    "$$\n",
    "\\frac{t_1}{t_1 +f_1} = \\frac{t_2}{t_2+f_2}\n",
    "\\qquad\\Longrightarrow\\qquad\n",
    "\\frac{\\displaystyle\\frac{t_2p_1}{p_2}}{\\displaystyle\\frac{t_2p_1}{p_2}+\\frac{f_2n_1}{n_2}}\n",
    "=\n",
    "\\frac{t_2}{t_2+f_2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The last of these used the first two and, when simplified, implies that\n",
    "\n",
    "$$\n",
    "\\frac{t_2}{t_2+f_2}\n",
    "=\n",
    "\\frac{t_2}{\\displaystyle t_2 +f_2\\frac{n_1}{n_2}\\frac{p_2}{p_1}}\n",
    "\\qquad\\Longrightarrow\\qquad\n",
    "f_1, f_2=0\\quad\\text{ or }\\quad\n",
    "\\frac{p_1}{n_1} =\\frac{p_2}{n_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Implication\n",
    "\n",
    "Fairness, in the sense described above, is probably not possible in general.\n",
    "If the three measures above are to be indifferent to the two groups then:\n",
    "\n",
    "- **Either:** the classifier is a perfect predictor for positive results in the\n",
    "sense that each $f_i$, the numbers of FP's, is zero.\n",
    "\n",
    "- **Or:** the ratios of positives to negatives are equal in each group.\n",
    "\n",
    "Both of these are unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Closing Thoughts\n",
    "\n",
    "You are referred to Sumpter's article for more details where, in particular,\n",
    "we hear that solving this **fairness dilemma** is not a technical matter but\n",
    "rather one of **ethics**.\n",
    "\n",
    "Data Science is more than just computation. It is important to be aware of the\n",
    "wider contexct in which we operate, as well as the limitations of our models\n",
    "and methods.\n",
    "\n",
    "What do you think?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Technical Notes, Production and Archiving\n",
    "\n",
    "Ignore the material below. What follows is not relevant to the material being taught."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Production Workflow\n",
    "\n",
    "- Finalise the notebook material above\n",
    "- Clear and fresh run of entire notebook\n",
    "- Create html slide show:\n",
    "  - `jupyter nbconvert --to slides 4_concepts.ipynb `\n",
    "- Set `OUTPUTTING=1` below\n",
    "- Comment out the display of web-sourced diagrams\n",
    "- Clear and fresh run of entire notebook\n",
    "- Comment back in the display of web-sourced diagrams\n",
    "- Clear all cell output\n",
    "- Set `OUTPUTTING=0` below\n",
    "- Save\n",
    "- git add, commit and push to FML\n",
    "- copy PDF, HTML etc to web site\n",
    "  - git add, commit and push\n",
    "- rebuild binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some of this originated from\n",
    "\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n",
    "\n",
    "These lines create a back up of the notebook. They can be ignored.\n",
    "\n",
    "At some point this is better as a bash script outside of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "NBROOTNAME='4_concepts'\n",
    "OUTPUTTING=0\n",
    "\n",
    "if [ $OUTPUTTING -eq 1 ]; then\n",
    "  jupyter nbconvert --to html $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.html ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.html\n",
    "  mv -f $NBROOTNAME.html ./formats/html/\n",
    "\n",
    "  jupyter nbconvert --to pdf $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.pdf ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.pdf\n",
    "  mv -f $NBROOTNAME.pdf ./formats/pdf/\n",
    "\n",
    "  jupyter nbconvert --to script $NBROOTNAME.ipynb\n",
    "  cp $NBROOTNAME.py ../backups/$(date +\"%m_%d_%Y-%H%M%S\")_$NBROOTNAME.py\n",
    "  mv -f $NBROOTNAME.py ./formats/py/\n",
    "else\n",
    "  echo 'Not Generating html, pdf and py output versions'\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
